<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="NanBlog 稀饭目标">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="NanBlog 稀饭目标">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="porridge42">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>NanBlog 稀饭目标</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">NanBlog 稀饭目标</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-fa fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/18/sklearn/10_%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/12/18/sklearn/10_%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">P10_决策树</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-18 16:53:00" itemprop="dateCreated datePublished" datetime="2023-12-18T16:53:00+08:00">2023-12-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-29 12:09:29" itemprop="dateModified" datetime="2023-12-29T12:09:29+08:00">2023-12-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="认识决策树"><a href="#认识决策树" class="headerlink" title="认识决策树"></a>认识决策树</h3><ul>
<li>决策树的思想来源非常朴素，；程序设计中的条件分支结构就是if-else结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法</li>
<li>例子：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231219102416.png"></li>
<li>为什么吧年龄放在最上面判断？<ul>
<li>首先判断年龄可以排除更多不符合的选项</li>
<li>如何确定判断的顺序是决策树算法需要做到的关键</li>
</ul>
</li>
<li>通过下一个例子，理解决策树具体如何实现分类：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231219103759.png"></li>
<li>已知四个特征值，预测是否贷款<ul>
<li>先看年龄-&gt;信贷情况-&gt;工作（三层判断）</li>
<li>先看房子-&gt;工作（两层判断）</li>
</ul>
</li>
<li>由上面可知先看房子是更加高效的决策方法，我们需要使用数学的方式来找出最优决策方法。</li>
</ul>
<h3 id="信息熵与信息增益"><a href="#信息熵与信息增益" class="headerlink" title="信息熵与信息增益"></a>信息熵与信息增益</h3><ul>
<li><strong>信息熵的定义：</strong><ul>
<li>H的专业术语称之为信息熵，单位为比特。<br>$$<br>H(X) &#x3D; -\sum_{i&#x3D;1}^{n}P(x_i)log_bP(x_i)<br>$$</li>
</ul>
</li>
<li><strong>决策树的划分依据之一：信息增益</strong><ul>
<li>定义与公式<br>特征A对训练数据集D的信息增益g(D,A)，定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差，即公式为：<br>$$<br>g(D, A) &#x3D; H(D) - H(D|A)<br>$$<br>公式的详细解释：</li>
</ul>
</li>
<li>信息熵的计算：<br>$$<br>H(D) &#x3D; -\sum_{k&#x3D;1}^{K}\frac{|C_k|}{|D|}log_b\frac{|C_k|}{|D|}<br>$$</li>
<li>条件熵的计算：<br>$$<br>H(D|A) &#x3D; \sum_{i&#x3D;1}^{n}\frac{|D_i|}{D}H(D_i)&#x3D;-\sum_{i&#x3D;1}^{n}\frac{|D_ik|}{|D_i|}log_b\frac{|D_ik|}{|D_i|}<br>$$<br>注：C_k表示属于某个类别的样本数<blockquote>
<p>信息熵增益表示得知特征x的信息而信息的不确定性减少的程度使得类Y的信息熵减少的程度</p>
</blockquote>
</li>
<li>决策树的原理不治信息增益这一种，还有其他几个原理类似的方案：<ul>
<li>ID3<ul>
<li>信息增益 最大的准则</li>
</ul>
</li>
<li>C4.5<ul>
<li>信息增益比 最大的准则</li>
</ul>
</li>
<li>CART<ul>
<li>分类树：基尼系数 最小的准则 在sklearn仲可以选择划分的默认原则</li>
<li>优势：划分更加细致（从后面的例子数显示来理解）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="决策树API"><a href="#决策树API" class="headerlink" title="决策树API"></a>决策树API</h3><ul>
<li><p>class sklearn.tree.DecisionTreeClassifier(criterion&#x3D;’gini’, max_depth&#x3D;None, random_state&#x3D;None)</p>
<ul>
<li>决策树分类器</li>
<li>criterion默认是’qini’下属，也可以选择信息增益的上’entropy’</li>
<li>max_depth：树的深度大小</li>
<li>random_state：随机数种子</li>
</ul>
</li>
<li><p>对比决策树与knn算法</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knn</span>():</span><br><span class="line">    <span class="comment"># 使用knn算法对鸢尾花进行分类</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1) 获取数据</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2) 划分数据集</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3) 特征工程：标准化</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4) KNN算法预估器</span></span><br><span class="line">    estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5) 模型评估</span></span><br><span class="line">    <span class="comment"># 方法1：直接比对真实值和预测值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方法2：计算准确率</span></span><br><span class="line">    score = estimator.score(x_test, y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tree</span>():</span><br><span class="line">    <span class="comment"># 使用决策树算法对鸢尾花进行分类</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1) 获取数据</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2) 划分数据集</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3) 决策树算法预估器</span></span><br><span class="line">    estimator = DecisionTreeClassifier(criterion=<span class="string">&quot;entropy&quot;</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4) 模型评估</span></span><br><span class="line">    <span class="comment"># 方法1：直接比对真实值和预测值</span></span><br><span class="line">    y_predict = estimator.predict(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方法2：计算准确率</span></span><br><span class="line">    score = estimator.score(x_test, y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;使用knn算法对鸢尾花进行分类：\n&quot;</span>)</span><br><span class="line">    knn()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;使用决策树算法对鸢尾花进行分类：\n&quot;</span>)</span><br><span class="line">    tree()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231229112849.png"></p>
</li>
</ul>
<h3 id="决策树可视化"><a href="#决策树可视化" class="headerlink" title="决策树可视化"></a>决策树可视化</h3><h4 id="保存树的结构到dot文件"><a href="#保存树的结构到dot文件" class="headerlink" title="保存树的结构到dot文件"></a>保存树的结构到dot文件</h4><ul>
<li>sklearn.tree.export_graphviz()该函数能导出DOT格式<ul>
<li>tree.export_graphviz(estimator, out_file&#x3D;’tree.dot’, feature_names&#x3D;[“,”])<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">    </span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">estimator = DecisionTreeClassifier(criterion=<span class="string">&quot;entropy&quot;</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">export_graphviz(estimator, out_file=<span class="string">&#x27;iris_tree.dot&#x27;</span>, feature_names=iris.feature_names)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>导出dot文件的内容：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">digraph Tree &#123;</span><br><span class="line">node [shape=box] ;</span><br><span class="line">0 [label=&quot;petal width (cm) &lt;= 0.8\nentropy = 1.581\nsamples = 112\nvalue = [37, 34, 41]&quot;] ;</span><br><span class="line">1 [label=&quot;entropy = 0.0\nsamples = 37\nvalue = [37, 0, 0]&quot;] ;</span><br><span class="line">0 -&gt; 1 [labeldistance=2.5, labelangle=45, headlabel=&quot;True&quot;] ;</span><br><span class="line">2 [label=&quot;petal width (cm) &lt;= 1.65\nentropy = 0.994\nsamples = 75\nvalue = [0, 34, 41]&quot;] ;</span><br><span class="line">0 -&gt; 2 [labeldistance=2.5, labelangle=-45, headlabel=&quot;False&quot;] ;</span><br><span class="line">3 [label=&quot;petal length (cm) &lt;= 4.95\nentropy = 0.494\nsamples = 37\nvalue = [0, 33, 4]&quot;] ;</span><br><span class="line">2 -&gt; 3 ;</span><br><span class="line">4 [label=&quot;entropy = 0.0\nsamples = 32\nvalue = [0, 32, 0]&quot;] ;</span><br><span class="line">3 -&gt; 4 ;</span><br><span class="line">5 [label=&quot;petal width (cm) &lt;= 1.55\nentropy = 0.722\nsamples = 5\nvalue = [0, 1, 4]&quot;] ;</span><br><span class="line">3 -&gt; 5 ;</span><br><span class="line">6 [label=&quot;entropy = 0.0\nsamples = 3\nvalue = [0, 0, 3]&quot;] ;</span><br><span class="line">5 -&gt; 6 ;</span><br><span class="line">7 [label=&quot;petal length (cm) &lt;= 5.45\nentropy = 1.0\nsamples = 2\nvalue = [0, 1, 1]&quot;] ;</span><br><span class="line">5 -&gt; 7 ;</span><br><span class="line">8 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]&quot;] ;</span><br><span class="line">7 -&gt; 8 ;</span><br><span class="line">9 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]&quot;] ;</span><br><span class="line">7 -&gt; 9 ;</span><br><span class="line">10 [label=&quot;petal length (cm) &lt;= 4.85\nentropy = 0.176\nsamples = 38\nvalue = [0, 1, 37]&quot;] ;</span><br><span class="line">2 -&gt; 10 ;</span><br><span class="line">11 [label=&quot;sepal width (cm) &lt;= 3.1\nentropy = 0.811\nsamples = 4\nvalue = [0, 1, 3]&quot;] ;</span><br><span class="line">10 -&gt; 11 ;</span><br><span class="line">12 [label=&quot;entropy = 0.0\nsamples = 3\nvalue = [0, 0, 3]&quot;] ;</span><br><span class="line">11 -&gt; 12 ;</span><br><span class="line">13 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]&quot;] ;</span><br><span class="line">11 -&gt; 13 ;</span><br><span class="line">14 [label=&quot;entropy = 0.0\nsamples = 34\nvalue = [0, 0, 34]&quot;] ;</span><br><span class="line">10 -&gt; 14 ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>可以使用在线网站或者其它工具查看dot文件生成的树状图：<ul>
<li><a target="_blank" rel="noopener" href="http://webgraphviz.com/">http://webgraphviz.com/</a></li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">digraph Tree &#123;</span><br><span class="line">node [shape=box] ;</span><br><span class="line">0 [label=&quot;petal width (cm) &lt;= 0.8\nentropy = 1.581\nsamples = 112\nvalue = [37, 34, 41]&quot;] ;</span><br><span class="line">1 [label=&quot;entropy = 0.0\nsamples = 37\nvalue = [37, 0, 0]&quot;] ;</span><br><span class="line">0 -&gt; 1 [labeldistance=2.5, labelangle=45, headlabel=&quot;True&quot;] ;</span><br><span class="line">2 [label=&quot;petal width (cm) &lt;= 1.65\nentropy = 0.994\nsamples = 75\nvalue = [0, 34, 41]&quot;] ;</span><br><span class="line">0 -&gt; 2 [labeldistance=2.5, labelangle=-45, headlabel=&quot;False&quot;] ;</span><br><span class="line">3 [label=&quot;petal length (cm) &lt;= 4.95\nentropy = 0.494\nsamples = 37\nvalue = [0, 33, 4]&quot;] ;</span><br><span class="line">2 -&gt; 3 ;</span><br><span class="line">4 [label=&quot;entropy = 0.0\nsamples = 32\nvalue = [0, 32, 0]&quot;] ;</span><br><span class="line">3 -&gt; 4 ;</span><br><span class="line">5 [label=&quot;petal width (cm) &lt;= 1.55\nentropy = 0.722\nsamples = 5\nvalue = [0, 1, 4]&quot;] ;</span><br><span class="line">3 -&gt; 5 ;</span><br><span class="line">6 [label=&quot;entropy = 0.0\nsamples = 3\nvalue = [0, 0, 3]&quot;] ;</span><br><span class="line">5 -&gt; 6 ;</span><br><span class="line">7 [label=&quot;petal length (cm) &lt;= 5.45\nentropy = 1.0\nsamples = 2\nvalue = [0, 1, 1]&quot;] ;</span><br><span class="line">5 -&gt; 7 ;</span><br><span class="line">8 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]&quot;] ;</span><br><span class="line">7 -&gt; 8 ;</span><br><span class="line">9 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 0, 1]&quot;] ;</span><br><span class="line">7 -&gt; 9 ;</span><br><span class="line">10 [label=&quot;petal length (cm) &lt;= 4.85\nentropy = 0.176\nsamples = 38\nvalue = [0, 1, 37]&quot;] ;</span><br><span class="line">2 -&gt; 10 ;</span><br><span class="line">11 [label=&quot;sepal width (cm) &lt;= 3.1\nentropy = 0.811\nsamples = 4\nvalue = [0, 1, 3]&quot;] ;</span><br><span class="line">10 -&gt; 11 ;</span><br><span class="line">12 [label=&quot;entropy = 0.0\nsamples = 3\nvalue = [0, 0, 3]&quot;] ;</span><br><span class="line">11 -&gt; 12 ;</span><br><span class="line">13 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 1, 0]&quot;] ;</span><br><span class="line">11 -&gt; 13 ;</span><br><span class="line">14 [label=&quot;entropy = 0.0\nsamples = 34\nvalue = [0, 0, 34]&quot;] ;</span><br><span class="line">10 -&gt; 14 ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="决策树总结"><a href="#决策树总结" class="headerlink" title="决策树总结"></a>决策树总结</h3><ul>
<li>优点：<ul>
<li>简单的理解和解释，树木可视化</li>
<li>可解释能力强</li>
</ul>
</li>
<li>缺点：<ul>
<li>决策树可能过于复杂，容易导致过拟合</li>
</ul>
</li>
<li>改进：<ul>
<li>减cart算法（决策树API中已经实现，随机森林参数调优有相关介绍）</li>
<li>随机森林</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/17/sklearn/9_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/12/17/sklearn/9_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">P9_朴素贝叶斯算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-17 20:01:00" itemprop="dateCreated datePublished" datetime="2023-12-17T20:01:00+08:00">2023-12-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-18 16:46:01" itemprop="dateModified" datetime="2023-12-18T16:46:01+08:00">2023-12-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="概率基础"><a href="#概率基础" class="headerlink" title="概率基础"></a>概率基础</h3><ul>
<li>概率定义为一件事情发生的可能性<ul>
<li>扔出一枚硬币，结果头像朝上</li>
</ul>
</li>
<li>P(X)：取值在[0,1]</li>
</ul>
<h4 id="女神是否喜欢计算案例"><a href="#女神是否喜欢计算案例" class="headerlink" title="女神是否喜欢计算案例"></a>女神是否喜欢计算案例</h4><p>在将这两个概率之前，通过一个例子，来计算一些结果：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231217210247.png"></p>
<ul>
<li>问题如下：<ol>
<li>女神喜欢的概率？<ul>
<li>P(喜欢) &#x3D; 4&#x2F;7</li>
</ul>
</li>
<li>职业是程序员并且体型匀称的概率？<ul>
<li>P(程序员, 匀称) &#x3D; 1&#x2F;7</li>
</ul>
</li>
<li>在女神喜欢的条件下，职业是程序员的概率？<ul>
<li>P(程序员|喜欢) &#x3D; 2&#x2F;4 &#x3D; 1&#x2F;2</li>
</ul>
</li>
<li>在女神喜欢的条件下，职业是程序员，体重是超重的概率？<ul>
<li>P(程序员, 超重|喜欢) &#x3D; 1&#x2F;4</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="联合概率、条件概率与相互独立"><a href="#联合概率、条件概率与相互独立" class="headerlink" title="联合概率、条件概率与相互独立"></a>联合概率、条件概率与相互独立</h3><ul>
<li>联合概率：包含多个条件，且所有条件同时成立的概率<ul>
<li>记作：P(A, B)</li>
<li>例如：P(程序员，匀称)，P(程序员,超重|喜欢)</li>
</ul>
</li>
<li>条件概率：就是事件A在另一个事件B已经发生的条件下的发生概率。<ul>
<li>记作：P(A|B)</li>
<li>例如：P(程序员|喜欢)，P(程序员，超重|喜欢)</li>
</ul>
</li>
<li>相互独立：如果P(A，B) &#x3D; P(A)P(B)，则称事件A与事件B相互独立。<ul>
<li><strong>P(A, B) &#x3D; P(A)P(B) &lt;&#x3D;&gt; 事件A与事件B相互独立</strong></li>
</ul>
</li>
</ul>
<h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h3><ul>
<li>公式<br>$$<br>P(C|W) &#x3D; \frac{P(W|C)P(C)}{P(W)}<br>$$<br>注：w为给定文档的特征值（频数统计，预测文档提供），c为文档化类别<br/></li>
</ul>
<h4 id="计算案例"><a href="#计算案例" class="headerlink" title="计算案例"></a>计算案例</h4><p>用上面问题中的数据带入贝叶斯公式：</p>
<blockquote>
<p>$$<br>P(喜欢|产品, 超重) &#x3D; \frac{P(产品, 超重|喜欢)P(喜欢)}{P(产品, 超重)}<br>$$</p>
</blockquote>
<p>上式中，P(产品, 超重|喜欢)和P(产品,超重)的结果均为0，导致无法计算结果。这是因为我们的样本量太少了，不具有代表性，本来现实生活中，肯定是存在职业是产品经理并且体重超重搞得人的，P(产品, 超重)不肯为0；而且事件“职业是产品经理”和事件“体重超重”通常被认为是相互独立的事件，但是，根据我们有限的7个样本计算“P(产品, 超重)&#x3D;P(产品)*P(超重)”不成立。<br>而朴素贝叶斯可以帮我们解决这个问题。<br>朴素贝叶斯，简单理解，就是假定了特征与特征之间相互独立的贝叶斯公式。<br>也就是说，朴素贝叶斯，之所以朴素，就在于假定了特征与特征相互独立。<br>所以，上面问题如果按照朴素贝叶斯的思路来解决，就可以是</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P(产品, 超重) = P(产品)*P(超重) = <span class="number">2</span>/<span class="number">7</span> * <span class="number">3</span>/<span class="number">7</span> = <span class="number">6</span>/<span class="number">49</span></span><br><span class="line">P(产品, 超重|喜欢) = P(产品|喜欢)*P(超重|喜欢) = <span class="number">1</span>/<span class="number">2</span> * <span class="number">1</span>/<span class="number">4</span> = <span class="number">1</span>/<span class="number">8</span></span><br><span class="line">P(喜欢|产品, 超重) = P(产品, 超重|喜欢)P(喜欢)/P(产品, 超重) = <span class="number">1</span>/<span class="number">8</span> *<span class="number">4</span>/<span class="number">7</span> / <span class="number">6</span>/<span class="number">49</span> = <span class="number">7</span>/<span class="number">12</span></span><br></pre></td></tr></table></figure>
<ul>
<li>朴素的意义：<ul>
<li>假设：<ul>
<li>假定特征与特征之间相互独立。</li>
<li>P(产品经理, 超重) &#x3D; P(产品)*P(超重)</li>
</ul>
</li>
</ul>
</li>
<li>朴素贝叶斯：<ul>
<li>朴素 + 贝叶斯公式</li>
</ul>
</li>
<li>应用场景：<ul>
<li>常用于文本分类<ul>
<li>以单词为特征（通常认为单词之间相互独立）<br/></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>那么这个公式如果在文章分类的场景中，我们可以这样看：<br>$$<br>P(C|F1, F2, …) &#x3D; \frac{P(F1, F2, …|C)P(C)}{P(F1, F2, …)}<br>$$<br>其中c可以是不同类别</p>
<ul>
<li>P(C)：每个文档类别的概率（某文档类别数&#x2F;总文档数量）</li>
<li>P(W|C)：给定类别下特征（被预测文档中出现的词）的概率<ul>
<li>计算方法：P(F1|C) &#x3D; Ni&#x2F;N (训练文档中去计算)<ul>
<li>Ni为该F1词在C类别所有文档中出现的次数</li>
<li>N为所属类别C下的文档中所有词出现的次数和</li>
</ul>
</li>
</ul>
</li>
<li>P(F1, F2, …)预测文档中每个词的概率</li>
</ul>
<p>如果计算两个类别概率比较：<br><strong>所以我们只要比较前面的大小就可以，得出谁的概率大</strong></p>
<h3 id="文章分类计算"><a href="#文章分类计算" class="headerlink" title="文章分类计算"></a>文章分类计算</h3><p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231218110251.png"></p>
<ul>
<li>计算结果<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P(Chinese|C) = <span class="number">5</span>/<span class="number">8</span></span><br><span class="line">P(Tokyo|C) = <span class="number">0</span></span><br><span class="line">P(Japan|C) = <span class="number">0</span></span><br></pre></td></tr></table></figure></li>
<li>这里因为样本太少，出现了概率为0的情况，为了解决这种情况，需要引入拉普拉斯平滑系数</li>
</ul>
<h4 id="拉普拉斯平滑系数"><a href="#拉普拉斯平滑系数" class="headerlink" title="拉普拉斯平滑系数"></a>拉普拉斯平滑系数</h4><p>目的：防止计算出的分类概率为0<br>$$<br>P(F1|C) &#x3D;  \frac{Ni+\alpha}{N+\alpha m}<br>$$<br>$\alpha$为指定的系数一般为1，m为训练文档中统计出的<strong>特征词</strong>的个数</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P(Chinese|C) = (<span class="number">5</span>+<span class="number">1</span>) / (<span class="number">8</span>+<span class="number">1</span>*<span class="number">6</span>) = <span class="number">6</span>/<span class="number">14</span> = <span class="number">3</span>/<span class="number">7</span></span><br><span class="line">P(Tokyo|C) = (<span class="number">0</span>+<span class="number">1</span>) / (<span class="number">8</span>+<span class="number">1</span>*<span class="number">6</span>) = <span class="number">1</span>/<span class="number">14</span></span><br><span class="line">P(Japan|C) = (<span class="number">0</span>+<span class="number">1</span>) / (<span class="number">8</span>+<span class="number">1</span>*<span class="number">6</span>) = <span class="number">1</span>/<span class="number">14</span></span><br></pre></td></tr></table></figure>
<h3 id="朴素贝叶斯分类算法API"><a href="#朴素贝叶斯分类算法API" class="headerlink" title="朴素贝叶斯分类算法API"></a>朴素贝叶斯分类算法API</h3><ul>
<li>sklearn.naive_bayes.MultinomialNB(aplha &#x3D; 1.0)<ul>
<li>朴素贝叶斯分类</li>
<li>aplpha：拉普拉斯平滑系数</li>
</ul>
</li>
</ul>
<h3 id="案例：20类新闻分类"><a href="#案例：20类新闻分类" class="headerlink" title="案例：20类新闻分类"></a>案例：20类新闻分类</h3><p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231218114613.png"></p>
<h4 id="步骤分析"><a href="#步骤分析" class="headerlink" title="步骤分析"></a>步骤分析</h4><ol>
<li>获取数据</li>
<li>划分数据集</li>
<li>特征工程<br>  文本特征抽取（TFIDF）</li>
<li>朴素贝叶斯预估器流程</li>
<li>模型评估</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1) 获取数据</span></span><br><span class="line">news = fetch_20newsgroups(subset=<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 特征工程：文本特征抽取-tfidf</span></span><br><span class="line">transfer = TfidfVectorizer()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) 朴素贝叶斯算法预估器流程</span></span><br><span class="line">estimator = MultinomialNB()</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5) 模型评估</span></span><br><span class="line"><span class="comment">#直接比对真实值与预测值：</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接比对真实值与预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"><span class="comment">#计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231218160652.png"></p>
<h3 id="朴素贝叶斯算法总结："><a href="#朴素贝叶斯算法总结：" class="headerlink" title="朴素贝叶斯算法总结："></a>朴素贝叶斯算法总结：</h3><ul>
<li>优点：<ul>
<li>朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。</li>
<li>对缺失值不太敏感，算法也比较简单，常用于文本分类。</li>
<li>分类准确度高（相对的），速度快。</li>
</ul>
</li>
<li>缺点：<ul>
<li>由于使用了样本属性独立性的假设，所以如果特征属性由于关联时其效果不好。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/08/sklearn/8_facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/12/08/sklearn/8_facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B/" class="post-title-link" itemprop="url">P8_facebook签到位置预测</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-08 16:08:00" itemprop="dateCreated datePublished" datetime="2023-12-08T16:08:00+08:00">2023-12-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-15 11:17:37" itemprop="dateModified" datetime="2023-12-15T11:17:37+08:00">2023-12-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="案例：预测facebook签到位置"><a href="#案例：预测facebook签到位置" class="headerlink" title="案例：预测facebook签到位置"></a>案例：预测facebook签到位置</h2><ul>
<li>数据集介绍：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231215105849.png"></li>
<li>流程分析：<ol>
<li>获取数据</li>
<li>处理数据<ul>
<li>目的：<br>特征值 x<br>目标值 y<ul>
<li>缩小数据范围<br>  2 &lt;  x &lt; 2.5<br>  1.0 &lt; y &lt; 1.5</li>
<li>time -&gt; 年月日时分秒</li>
<li>过滤签到次数少的地点</li>
</ul>
</li>
</ul>
</li>
<li>特征工程：标准化</li>
<li>KNN算法预估流程</li>
<li>模型选择与调优</li>
<li>模型评估</li>
</ol>
</li>
</ul>
<pre><code class="py">import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# 1.导入数据集
data = pd.read_csv(&quot;./FBlocation/train.csv&quot;)

# 2.基本数据处理
# 1) 缩小数据范围
data = data.query(&quot;x &lt; 2.5 &amp; x &gt; 2 &amp; y &lt; 1.5 &amp; y &gt; 1.0&quot;)

# 2) 处理时间特征
time_value = pd.to_datetime(data[&quot;time&quot;], unit=&quot;s&quot;)
date = pd.DatetimeIndex(time_value)
data[&quot;day&quot;] = date.day
data[&quot;weekday&quot;] = date.weekday
data[&quot;hour&quot;] = date.hour

# 3) 过滤签到次数少的地点
place_count = data.groupby(&quot;place_id&quot;).count()[&quot;row_id&quot;]
data[&quot;place_id&quot;].isin(place_count[place_count &gt; 3].index.values)
data_final = data[data[&quot;place_id&quot;].isin(place_count[place_count &gt; 3].index.values)]

# 筛选特征值和目标值
x = data_final[[&quot;x&quot;, &quot;y&quot;, &quot;accuracy&quot;, &quot;day&quot;, &quot;weekday&quot;, &quot;hour&quot;]]
y = data_final[&quot;place_id&quot;]

# 数据集划分
x_train, x_test, y_train, y_test = train_test_split(x, y)

# 特征工程：标准化
transfer = StandardScaler()
x_train = transfer.fit_transform(x_train)
x_test = transfer.transform(x_test)

# KNN算法预估器
estimator = KNeighborsClassifier(n_neighbors=3)

# 加入网格搜索交叉验证
# 参数准备
param_dict = &#123;&quot;n_neighbors&quot;: [1, 3, 5, 7, 9, 11]&#125;
estimator = GridSearchCV(estimator, param_grid=param_dict, cv=10)

estimator.fit(x_train, y_train)

# 模型评估
# 方法1：直接比对真实值和预测值
y_predict = estimator.predict(x_test)
print(&quot;y_predict:\n&quot;, y_predict)
print(&quot;直接比对真实值和预测值：\n&quot;, y_test == y_predict)

# 方法2：计算准确率
score = estimator.score(x_test, y_test)
print(&quot;准确率为：\n&quot;, score)

print(&quot;最佳参数：\n&quot;, estimator.best_params_)
print(&quot;最佳结果：\n&quot;, estimator.best_score_)
print(&quot;最佳估计器：\n&quot;, estimator.best_estimator_)
print(&quot;交叉验证结果：\n&quot;, estimator.cv_results_)
</code></pre>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231215111652.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/06/sklearn/7_sklearn%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/12/06/sklearn/7_sklearn%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98/" class="post-title-link" itemprop="url">P7_模型选择与调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-06 10:17:00" itemprop="dateCreated datePublished" datetime="2023-12-06T10:17:00+08:00">2023-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-12-08 16:07:32" itemprop="dateModified" datetime="2023-12-08T16:07:32+08:00">2023-12-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="模型选择与调优"><a href="#模型选择与调优" class="headerlink" title="模型选择与调优"></a>模型选择与调优</h2><h3 id="什么是交叉验证（Cross-Validation）："><a href="#什么是交叉验证（Cross-Validation）：" class="headerlink" title="什么是交叉验证（Cross Validation）："></a>什么是交叉验证（Cross Validation）：</h3><ul>
<li>交叉验证：将拿到的训练数据，分为训练和验证集。以下图为例：将数据分为4份，其中一份作为验证集。然后经过3次（组）的测试，每次都要更换不同的验证集。即得到4组模型的结果，平均值作为最终结果。又称4折交叉验证。<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231206185045.png"></li>
<li>为什么需要交叉验证：<ul>
<li>交叉验证的目的：<strong>为了让评估的模型更加准确可信</strong><blockquote>
<p>问题：交叉验证只是对于参数得出更好的结果，那么怎么选择或者调优参数？</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="超参数搜索-网格搜索（Grid-Search）"><a href="#超参数搜索-网格搜索（Grid-Search）" class="headerlink" title="超参数搜索-网格搜索（Grid Search）"></a>超参数搜索-网格搜索（Grid Search）</h3><ul>
<li>通常情况下，<strong>有很多参数是需要手动指定的（例如K近邻算法中的K值）, 这种叫超参数。</strong> 但是手动过程繁杂，所以需要对模型预设几种超参数组合。<strong>每种超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="left">K值</th>
<th align="right">K&#x3D;3</th>
<th>k&#x3D;5</th>
<th>k&#x3D;7</th>
</tr>
</thead>
<tbody><tr>
<td align="left">模型</td>
<td align="right">模型1</td>
<td>模型2</td>
<td>模型3</td>
</tr>
</tbody></table>
<ul>
<li>模型选择与调用API：<ul>
<li>sklearn.model_selection.GridSearchCV(estimator, param_grid&#x3D;None, cv&#x3D;None)<ul>
<li>对估计器的指定参数值进行详尽搜索</li>
<li>estimator：估计器对象</li>
<li>param_gtid：估计器参数(dict){“n_neighbors”:[1,3,5]}</li>
<li>cv：指定几折交叉验证</li>
<li>fit()：输入训练数据</li>
<li>score()：准确率</li>
<li>结果分析：<ul>
<li>最佳参数：<code>best_params_</code></li>
<li>最佳结果：<code>best_score_</code></li>
<li>最佳估计器：<code>best_estimator_</code></li>
<li>交叉验证结果：<code>cv_results_</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="鸢尾花案例增加K值调优"><a href="#鸢尾花案例增加K值调优" class="headerlink" title="鸢尾花案例增加K值调优"></a>鸢尾花案例增加K值调优</h3><ul>
<li>只用GridSearchCV构建预估器<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用knn算法对鸢尾花进行分类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1) 获取数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">114514</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) KNN算法预估器</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入网格搜索交叉验证</span></span><br><span class="line"><span class="comment"># 参数准备</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5) 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2：计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳参数：\n&quot;</span>, estimator.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳结果：\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳估计器：\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证结果：\n&quot;</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231207092922.png"></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/09/sklearn/6_KNN%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/09/sklearn/6_KNN%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">P6_KNN算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-09 09:50:00" itemprop="dateCreated datePublished" datetime="2023-11-09T09:50:00+08:00">2023-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-16 20:37:52" itemprop="dateModified" datetime="2023-11-16T20:37:52+08:00">2023-11-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="K-近邻算法学习目标"><a href="#K-近邻算法学习目标" class="headerlink" title="K-近邻算法学习目标"></a>K-近邻算法学习目标</h2><ul>
<li>学习目标：<ul>
<li>K-近邻算法的距离公式</li>
<li>K-近邻算饭的超参数K值以及取值问题</li>
<li>K-近邻算法的优缺点</li>
<li>应用KNeighbrosClassifier实现分类</li>
<li>了解分类算法的评估标准准确率</li>
</ul>
</li>
<li>应用：<ul>
<li>鸢尾花数据集预测</li>
<li>Facebook签到位置预测</li>
</ul>
</li>
<li>内容：<ul>
<li>什么是K-近邻算法</li>
<li>K-近邻算法API</li>
<li>案例：鸢尾花种类预测</li>
<li>K-近邻总结</li>
</ul>
</li>
</ul>
<h2 id="K-近邻算法-KNN-原理"><a href="#K-近邻算法-KNN-原理" class="headerlink" title="K-近邻算法(KNN)原理"></a>K-近邻算法(KNN)原理</h2><p>K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法，总体来说KNN算法是相对比较容易理解的算法</p>
<ul>
<li>定义<ul>
<li>若果一个样本在特征空间中的k个最相似（即特征空间中最邻近）的样本中大多数属于某一个类别，则该样本也属于这个类别。</li>
</ul>
</li>
<li>距离公式<ul>
<li>连个样本的距离可以通过如下公式计算，又叫欧氏距离</li>
<li>比如说：a(a1,a2,a3),b(b1,b2,b3)<br>$$<br>\sqrt{(a1-b1)^2+(a2-b2)^2+(a3-b3)^2}<br>$$</li>
</ul>
</li>
</ul>
<h2 id="K-近邻算法API"><a href="#K-近邻算法API" class="headerlink" title="K-近邻算法API"></a>K-近邻算法API</h2><ul>
<li>sklearn.neighbors.KNeighbrosClassifier(n_neighbors&#x3D;5, algorithm&#x3D;’auto’)<ul>
<li>n_neighbors：int,可选（默认为&#x3D;5），k_neighbors查询默认使用的邻居数</li>
<li>algorithm：{‘auto, ‘ball_ress, ‘kd_tree’, ‘brute’},可选用与计算最邻近邻居的算法：’ball_tree’将会使用BallTree,’kd_tree’将使用KDTree。’auto’将尝试根据传递给fit方法的值来决定最合适的算法。（不同实现方式影响效率）</li>
</ul>
</li>
</ul>
<h2 id="案例：鸢尾花种类预测"><a href="#案例：鸢尾花种类预测" class="headerlink" title="案例：鸢尾花种类预测"></a>案例：鸢尾花种类预测</h2><ul>
<li>数据集简介：<ul>
<li>示例数量：150（三个类各有50个）</li>
<li>属性数量：4（数值型，数值型，帮助预测的属性和类）</li>
<li><strong>Attribute Information:</strong><ul>
<li>sepal length 萼片长度（厘米）</li>
<li>sepal width 萼片宽度（厘米）</li>
<li>petal length 花瓣长度（厘米）</li>
<li>petal width 花瓣宽度（厘米）<ul>
<li><strong>class:</strong></li>
<li>Iris-Setosa 山鸢尾</li>
<li>Iris-Versicolour 变色鸢尾</li>
<li>Iris-Virginica 维吉尼亚鸢尾</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>流程规划：</strong></li>
</ul>
<ol>
<li>获取数据</li>
<li>划分数据集</li>
<li>特征工程-标准化</li>
<li>KNN算法预估器</li>
<li>模型评估<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用knn算法对鸢尾花进行分类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1) 获取数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">114514</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) KNN算法预估器</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5) 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2：计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231114144536.png"></li>
</ol>
<h2 id="KNN算法总结："><a href="#KNN算法总结：" class="headerlink" title="KNN算法总结："></a>KNN算法总结：</h2><ul>
<li>优点：<ul>
<li>简单，易于理解，易于实现，无需训练</li>
</ul>
</li>
<li>缺点：<ul>
<li>懒惰算法，对测试样本分类时的计算量打，内存开销大</li>
<li>必须指定K值，K值选择不当则分类精度不能保证</li>
</ul>
</li>
<li>使用场景：小数据场景，几千~几万样本具体场景具体业务与测试</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/07/sklearn/5_sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/07/sklearn/5_sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/" class="post-title-link" itemprop="url">P5_sklearn转换器和估计器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-07 19:54:00" itemprop="dateCreated datePublished" datetime="2023-11-07T19:54:00+08:00">2023-11-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-09 09:48:57" itemprop="dateModified" datetime="2023-11-09T09:48:57+08:00">2023-11-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分类算法-sklearn转换器与估计器"><a href="#分类算法-sklearn转换器与估计器" class="headerlink" title="分类算法-sklearn转换器与估计器"></a>分类算法-sklearn转换器与估计器</h1><h2 id="转换器"><a href="#转换器" class="headerlink" title="转换器"></a>转换器</h2><ul>
<li>回忆一下之前的特征工程步骤：<ul>
<li>1、实例化（实例化的是一个转换器类(Transformer)）</li>
<li>2、调用fit_transform（对于文档建立分类词频矩阵，不能同时调用）</li>
</ul>
</li>
<li>我们把特诊工程的结接口称之为转换器，其中转换器调用有这么几种形式<ul>
<li>fit_transform</li>
<li>fit</li>
<li>transform</li>
</ul>
</li>
</ul>
<h2 id="估计器（sklearn机器学习算法的实现）"><a href="#估计器（sklearn机器学习算法的实现）" class="headerlink" title="估计器（sklearn机器学习算法的实现）"></a>估计器（sklearn机器学习算法的实现）</h2><ul>
<li><p>在sklearn中，估计器(estimator)是一个重要的角色，是一类实现了算法的API</p>
<ul>
<li>1、用于分类的估计器：<ul>
<li>sklearn.neighbors k-近邻算法</li>
<li>sklearn.naive_bayes 贝叶斯</li>
<li>sklearn.linear_model.LogisticRegression 逻辑回归</li>
<li>sklearn.tree 决策树与随机森林</li>
</ul>
</li>
<li>2、用于回归的估计器：<ul>
<li>sklearn.linear_model.LinearRegression 线型回归</li>
<li>sklearn.linear_model.Ridge 岭回归</li>
</ul>
</li>
<li>3、用于无监督学习的估计器<ul>
<li>sklearn.cluster.KMeans 聚类<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/II4LU%7E7VRFUYWLNIXAJAV5F.png"></li>
</ul>
</li>
</ul>
</li>
<li><p>估计器的使用：</p>
<ul>
<li>1、实例化一个estimator</li>
<li>2、estimator.fit(x_tran, y_tran) 计算<ul>
<li>–调用完毕，模型生成</li>
</ul>
</li>
<li>3、模型评估：<ol>
<li>直接比对真实值和预测值<br>y_predict &#x3D; estimator.predict(x_test)<br>y_test &#x3D;&#x3D; y_predict </li>
<li>计算准确率<br>estimator.score(x_test, y_test)</li>
</ol>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/05/sklearn/4_sklearn%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/05/sklearn/4_sklearn%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/" class="post-title-link" itemprop="url">P4_sklearn特征降维</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-05 11:05:00" itemprop="dateCreated datePublished" datetime="2023-11-05T11:05:00+08:00">2023-11-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-07 19:50:49" itemprop="dateModified" datetime="2023-11-07T19:50:49+08:00">2023-11-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="特征工程-降维"><a href="#特征工程-降维" class="headerlink" title="特征工程-降维"></a>特征工程-降维</h1><ul>
<li>学习目标：<ul>
<li>引用VarianceThreshold实现删除低方差特征</li>
<li>了解相关系数的特点和计算</li>
<li>应用相关系数实现特征选择</li>
</ul>
</li>
</ul>
<h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><strong>降维</strong>是只在某些限定条件下。<strong>降低随机变量（特征）个数</strong>，得到一组<strong>不相关</strong>的主变量的过程.</li>
</ul>
<p> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105130621.png"></p>
<ul>
<li>相关特征（什么是相关）<ul>
<li>例如：相对湿度与降雨量之间的相关.</li>
<li>等等…<blockquote>
<p>正是因为在训练的时候录，我们都是使用特征进行学习。如果特征本上存在问题或者特征之间相关性比较强，对算法学习预测会影响比较大</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="降维的两种方式："><a href="#降维的两种方式：" class="headerlink" title="降维的两种方式："></a>降维的两种方式：</h3><ul>
<li>特征选择</li>
<li>主成分分析（可以理解为一种特征提取的方式）<br/></li>
</ul>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="什么是特征选择"><a href="#什么是特征选择" class="headerlink" title="什么是特征选择"></a>什么是特征选择</h3><ul>
<li><p>定义： 数据中包含<strong>冗余或相关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出特征</strong>。<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105132916.png"></p>
<blockquote>
<p>如果在此处添加一个特征“知否有爪子”或者“是否有眼睛”类似的特征，明显就是属于冗余特征</p>
</blockquote>
</li>
<li><p>如何使用数学方法找出并去除数据中的冗余&#x2F;相关特征？</p>
</li>
<li><p><strong>方法：</strong></p>
<ul>
<li>Fillter(过滤式)：主要探究特征本身特点、特征与特征和目标之间关联<ul>
<li>方差选择法：低方差特征过滤</li>
<li>相关系数</li>
</ul>
</li>
<li>Embedded(嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul>
<li>决策树：信息熵、信息增益</li>
<li>正则化：L1、L2</li>
<li>深度学习：卷积等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="过滤式"><a href="#过滤式" class="headerlink" title="过滤式"></a>过滤式</h3><h4 id="方差选择法："><a href="#方差选择法：" class="headerlink" title="方差选择法："></a>方差选择法：</h4><ul>
<li><p>删除低方差的一些特征，在结合方差的大小来考虑这个方式的角度。</p>
<ul>
<li>特征方差小：某个特征大多样本的值都比较相近</li>
<li>特征方差大：某个特征很多样本呢的值都有差别</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
<ul>
<li>sklearn.feature_selection.VarianceThreshold(thrshold &#x3D; 0.0)<ul>
<li>删除所有低方差特征</li>
<li>Variance.fit_transform(ndrray[n_samples, n_features])</li>
<li>返回值：训练集相差异低于threshold的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。<br/></li>
</ul>
</li>
</ul>
</li>
<li><p>数据计算<br>我们对某些股票的指标特征之间进行一个筛选，数据在”factor_returns.csv”文件中，除去’index’,’data’,’return’列不考虑（这些类型不匹配，也不是所需要的指标）<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203605.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、导入数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./factor_returns.csv&#x27;</span>)</span><br><span class="line">data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data：\n&quot;</span>, data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、初始化VarianceThreshold并制定方差阈值</span></span><br><span class="line">transfer = VarianceThreshold(threshold = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, pd.DataFrame(data_new))</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203744.png"><br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203807.png"></p>
</li>
</ul>
<h4 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h4><ul>
<li><p>皮尔逊相关系数（Pearson Correlation Coefficient）</p>
<ul>
<li>反应变量之间相关关系密切程度的统计指标</li>
</ul>
</li>
<li><p>公式<br>$$<br>r &#x3D; \frac{n\Sigma xy - \Sigma x \Sigma y}<br>{\sqrt{n\Sigma x^2 - (\Sigma x)^2}\sqrt{n\Sigma y^2 - (\Sigma y)^2}}<br>$$<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106092011.png"><br>&#x3D; 0.9942<br><strong>所以我们最终得出结论是广告投入费与月平均销售额之间有高度的正相关关系。</strong></p>
<br/>
</li>
<li><p><strong>特点：</strong></p>
</li>
<li><p>相关系数的值介于$-1$与$1$之间，即$-1\le r\le 1$。其性质如下：</p>
<ul>
<li>当$r&gt;0$时，表示两变量正相关，$r&lt;0$时，两变量为负相关</li>
<li>当$0&lt;|r|&lt;1$时,表示两变量为完全相关，当$r&#x3D;0$时，表示两变量间无相关关系</li>
<li>当$0&lt;|r|&lt;1$时，表示两变量存在一定程度的相关。且$|r|$越接近1，两变量间线性关系月密切；$|r|$越接近与$0$，表示两变量的线性相关越弱</li>
<li>一般可按三级划分：$|r|&lt;0.4$为低度相关；$0.4\le |r|&lt;0.7$为显著性相关；$0.7\le |r|&lt;1$为高度线型相关</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
<ul>
<li>from scipu.stats import pearsonr<ul>
<li>x：(N,) array_like</li>
<li>y：(N,) array_like</li>
<li>返回值：Pearson相关系数<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./factor_returns.csv&#x27;</span>)</span><br><span class="line">data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">transfer = VarianceThreshold(threshold = <span class="number">10</span>)</span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算两个变量之间的相关系数</span></span><br><span class="line">r1 = pearsonr(data[<span class="string">&quot;pe_ratio&quot;</span>], data[<span class="string">&quot;pb_ratio&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pe_ratio与pb_ratio之间的相关系数：\n&quot;</span>, r1)</span><br><span class="line">r2 = pearsonr(data[<span class="string">&quot;revenue&quot;</span>], data[<span class="string">&quot;total_expense&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;revenue与total_expense之间的相关系数：\n&quot;</span>, r2)</span><br></pre></td></tr></table></figure>
输出：<br>pe_ratio与pb_ratio之间的相关系数：<br> (-0.004389322779936285, 0.8327205496564927)<br>revenue与total_expense之间的相关系数：<br> (0.99584504131361, 0.0)</li>
</ul>
</li>
</ul>
</li>
<li><p>当两个特征变量相关型很高时如何操作：</p>
<ul>
<li>选取其中一个</li>
<li>加权求和</li>
<li>主成分分析</li>
</ul>
</li>
</ul>
<h4 id="主成分分析："><a href="#主成分分析：" class="headerlink" title="主成分分析："></a>主成分分析：</h4><ul>
<li><p>什么是主成分分析(PCA)：</p>
<ul>
<li>定义：<strong>高维数据转换为低维数据的过程</strong>，在此过程中可能会<strong>舍弃原有数据、创造新的变量</strong></li>
<li>作用：<strong>是数据维数压缩，尽可能降低元数据的维数（复杂度），损失少量的信息。</strong></li>
<li>应用：回归分析或者聚类分析当中</li>
<li>原理简介：<br>假设对于给定的5个点，数据如下：<br><code>(-1, -2), (-1, 0), (0, 0), (2, 1), (0, 1)</code><br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106155048.png"><br>要求将这个二维的数据简成一维，并算是少量的信息<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106155220.png"><br><strong>找到一个合适的直线，通过一个矩阵运算得出主成分分析的结果</strong><br>$$<br>Y&#x3D;(\frac{1}{\sqrt{2}}\enspace\frac{1}{\sqrt{2}})<br>\begin{pmatrix}-1&amp;-1&amp;0&amp;2&amp;0\newline-2&amp;0&amp;0&amp;1&amp;1\end{pmatrix}<br>&#x3D;(\frac{-3}{\sqrt{2}}\enspace\frac{-1}{\sqrt{2}}\enspace 0\enspace\frac{3}{\sqrt{2}}\enspace\frac{-1}{\sqrt{2}})<br>$$</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
</li>
<li><p>sklearn.decomposition.PCA(n_components&#x3D;None)</p>
<ul>
<li>将数据分解为较低维数空间</li>
<li>n_components：<ul>
<li>小数：表示保留百分之多少的信息</li>
<li>整数：减少到多少特征</li>
</ul>
</li>
<li>PCA.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后指定维度的array</li>
</ul>
</li>
<li><p>计算示例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106195504.png"></p>
</li>
</ul>
<h2 id="案例：探究用户对物品分类的喜好细分降维"><a href="#案例：探究用户对物品分类的喜好细分降维" class="headerlink" title="案例：探究用户对物品分类的喜好细分降维"></a>案例：探究用户对物品分类的喜好细分降维</h2><ul>
<li>数据如下：<ul>
<li>order_products_prior.csv：订单与商品信息<ul>
<li>字段：<strong>order_id, product_id,</strong> add_to_cart_order, reordered</li>
</ul>
</li>
<li>products.csv：商品信息<ul>
<li>字段：<strong>product_id,</strong> product_name, aisle_id, department_id</li>
</ul>
</li>
<li>orders.csv：用户的订单信息<ul>
<li>字段：<strong>order_id, user_id,</strong> eval_set, order_number, …</li>
</ul>
</li>
<li>aisles.csv：商品所属具体物品类别<ul>
<li>字段：<strong>aisle_id, aisle</strong><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">order_products = pd.read_csv(<span class="string">&quot;./instacart/order_products__prior.csv&quot;</span>)</span><br><span class="line">products = pd.read_csv(<span class="string">&quot;./instacart/products.csv&quot;</span>)</span><br><span class="line">orders = pd.read_csv(<span class="string">&quot;./instacart/orders.csv&quot;</span>)</span><br><span class="line">aisles = pd.read_csv(<span class="string">&quot;./instacart/aisles.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、合并表</span></span><br><span class="line">tab1 = pd.merge(aisles, products, on=[<span class="string">&quot;aisle_id&quot;</span>, <span class="string">&quot;aisle_id&quot;</span>])</span><br><span class="line">tab2 = pd.merge(tab1, order_products, on=[<span class="string">&quot;product_id&quot;</span>, <span class="string">&quot;product_id&quot;</span>])</span><br><span class="line">tab3 = pd.merge(tab2, orders, on=[<span class="string">&quot;order_id&quot;</span>, <span class="string">&quot;order_id&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;合并后的原始数据：\n&quot;</span>, tab3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、找到user_id和aisle之间的关系</span></span><br><span class="line">table = pd.crosstab(tab3[<span class="string">&quot;user_id&quot;</span>], tab3[<span class="string">&quot;aisle&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;user_id与aisle的交叉表：\n&quot;</span>, table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、PCA降维</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">data_new = transfer.fit_transform(table)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的数据：\n&quot;</span>, data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的维度：\n&quot;</span>, data_new.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><strong>输出：</strong><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">合并后的原始数据：</span><br><span class="line">           aisle_id                       aisle  product_id  \</span><br><span class="line"><span class="number">0</span>                <span class="number">1</span>       prepared soups salads         <span class="number">209</span>   </span><br><span class="line"><span class="number">1</span>                <span class="number">1</span>       prepared soups salads       <span class="number">22853</span>   </span><br><span class="line"><span class="number">2</span>                <span class="number">4</span>               instant foods       <span class="number">12087</span>   </span><br><span class="line"><span class="number">3</span>                <span class="number">4</span>               instant foods       <span class="number">47570</span>   </span><br><span class="line"><span class="number">4</span>               <span class="number">13</span>              prepared meals       <span class="number">10089</span>   </span><br><span class="line"><span class="meta">... </span>           ...                         ...         ...   </span><br><span class="line"><span class="number">32434484</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">47713</span>   </span><br><span class="line"><span class="number">32434485</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434486</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434487</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434488</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"></span><br><span class="line">                                      product_name  department_id  order_id  \</span><br><span class="line"><span class="number">0</span>                              Italian Pasta Salad             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">1</span>                                Pesto Pasta Salad             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">2</span>                 Chicken Flavor Ramen Noodle Soup              <span class="number">9</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">3</span>         Original Flavor Macaroni &amp; Cheese Dinner              <span class="number">9</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">4</span>                                           Dolmas             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="meta">... </span>                                           ...            ...       ...   </span><br><span class="line"><span class="number">32434484</span>                            Sparkling Rose              <span class="number">5</span>   <span class="number">3014872</span>   </span><br><span class="line"><span class="number">32434485</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>     <span class="number">34570</span>   </span><br><span class="line"><span class="number">32434486</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>    <span class="number">250923</span>   </span><br><span class="line"><span class="number">32434487</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>   <span class="number">1319402</span>   </span><br><span class="line"><span class="number">32434488</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>   <span class="number">2298986</span>   </span><br><span class="line"></span><br><span class="line">          add_to_cart_order  reordered  user_id eval_set  order_number  \</span><br><span class="line"><span class="number">0</span>                         <span class="number">5</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">1</span>                         <span class="number">4</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">2</span>                        <span class="number">15</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">3</span>                        <span class="number">14</span>          <span class="number">1</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">4</span>                        <span class="number">25</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="meta">... </span>                    ...        ...      ...      ...           ...   </span><br><span class="line"><span class="number">32434484</span>                  <span class="number">1</span>          <span class="number">0</span>    <span class="number">63218</span>    prior             <span class="number">1</span>   </span><br><span class="line"><span class="number">32434485</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">37901</span>    prior            <span class="number">13</span>   </span><br><span class="line"><span class="number">32434486</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">26431</span>    prior            <span class="number">27</span>   </span><br><span class="line"><span class="number">32434487</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">26431</span>    prior            <span class="number">34</span>   </span><br><span class="line"><span class="number">32434488</span>                  <span class="number">1</span>          <span class="number">0</span>    <span class="number">37901</span>    prior             <span class="number">9</span>   </span><br><span class="line"></span><br><span class="line">          order_dow  order_hour_of_day  days_since_prior_order  </span><br><span class="line"><span class="number">0</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">1</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">2</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">3</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">4</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="meta">... </span>            ...                ...                     ...  </span><br><span class="line"><span class="number">32434484</span>          <span class="number">1</span>                 <span class="number">14</span>                     NaN  </span><br><span class="line"><span class="number">32434485</span>          <span class="number">3</span>                  <span class="number">9</span>                    <span class="number">13.0</span>  </span><br><span class="line"><span class="number">32434486</span>          <span class="number">5</span>                 <span class="number">11</span>                    <span class="number">10.0</span>  </span><br><span class="line"><span class="number">32434487</span>          <span class="number">2</span>                 <span class="number">14</span>                     <span class="number">7.0</span>  </span><br><span class="line"><span class="number">32434488</span>          <span class="number">2</span>                 <span class="number">11</span>                    <span class="number">13.0</span>  </span><br><span class="line"></span><br><span class="line">[<span class="number">32434489</span> rows x <span class="number">14</span> columns]</span><br><span class="line">user_id与aisle的交叉表：</span><br><span class="line"> aisle    air fresheners candles  asian foods  baby accessories  \</span><br><span class="line">user_id                                                          </span><br><span class="line"><span class="number">1</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                             <span class="number">0</span>            <span class="number">3</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                             <span class="number">0</span>            <span class="number">2</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                        ...          ...               ...   </span><br><span class="line"><span class="number">206205</span>                        <span class="number">0</span>            <span class="number">0</span>                 <span class="number">1</span>   </span><br><span class="line"><span class="number">206206</span>                        <span class="number">0</span>            <span class="number">4</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                        <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                        <span class="number">0</span>            <span class="number">3</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                        <span class="number">0</span>            <span class="number">1</span>                 <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    baby bath body care  baby food formula  bakery desserts  \</span><br><span class="line">user_id                                                            </span><br><span class="line"><span class="number">1</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                     ...                ...              ...   </span><br><span class="line"><span class="number">206205</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                     <span class="number">0</span>                  <span class="number">1</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                     <span class="number">0</span>                  <span class="number">3</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    baking ingredients  baking supplies decor  beauty  beers coolers  \</span><br><span class="line">user_id                                                                     </span><br><span class="line"><span class="number">1</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                         <span class="number">2</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                    ...                    ...     ...            ...   </span><br><span class="line"><span class="number">206205</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                    <span class="number">4</span>                      <span class="number">1</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                    <span class="number">4</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    ...  spreads  tea  tofu meat alternatives  tortillas flat bread  \</span><br><span class="line">user_id  ...                                                               </span><br><span class="line"><span class="number">1</span>        ...        <span class="number">1</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>        ...        <span class="number">3</span>    <span class="number">1</span>                       <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>        ...        <span class="number">4</span>    <span class="number">1</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>        ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">1</span>   </span><br><span class="line"><span class="number">5</span>        ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>     ...      ...  ...                     ...                   ...   </span><br><span class="line"><span class="number">206205</span>   ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>   ...        <span class="number">1</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>   ...        <span class="number">3</span>    <span class="number">4</span>                       <span class="number">0</span>                     <span class="number">2</span>   </span><br><span class="line"><span class="number">206208</span>   ...        <span class="number">5</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">7</span>   </span><br><span class="line"><span class="number">206209</span>   ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    trail mix snack mix  trash bags liners  vitamins supplements  \</span><br><span class="line">user_id                                                                 </span><br><span class="line"><span class="number">1</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                     ...                ...                   ...   </span><br><span class="line"><span class="number">206205</span>                     <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                     <span class="number">0</span>                  <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                     <span class="number">1</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                     <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                     <span class="number">0</span>                  <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    water seltzer sparkling water  white wines  yogurt  </span><br><span class="line">user_id                                                      </span><br><span class="line"><span class="number">1</span>                                    <span class="number">0</span>            <span class="number">0</span>       <span class="number">1</span>  </span><br><span class="line"><span class="number">2</span>                                    <span class="number">2</span>            <span class="number">0</span>      <span class="number">42</span>  </span><br><span class="line"><span class="number">3</span>                                    <span class="number">2</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">4</span>                                    <span class="number">1</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">5</span>                                    <span class="number">0</span>            <span class="number">0</span>       <span class="number">3</span>  </span><br><span class="line"><span class="meta">... </span>                               ...          ...     ...  </span><br><span class="line"><span class="number">206205</span>                               <span class="number">0</span>            <span class="number">0</span>       <span class="number">5</span>  </span><br><span class="line"><span class="number">206206</span>                               <span class="number">1</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">206207</span>                              <span class="number">11</span>            <span class="number">0</span>      <span class="number">15</span>  </span><br><span class="line"><span class="number">206208</span>                               <span class="number">0</span>            <span class="number">0</span>      <span class="number">33</span>  </span><br><span class="line"><span class="number">206209</span>                               <span class="number">0</span>            <span class="number">0</span>       <span class="number">3</span>  </span><br><span class="line"></span><br><span class="line">[<span class="number">206209</span> rows x <span class="number">134</span> columns]</span><br><span class="line"></span><br><span class="line">降维后的数据：</span><br><span class="line"> [[-<span class="number">24.21565874</span>   <span class="number">2.4294272</span>   -<span class="number">2.46636975</span> ...  -<span class="number">0.08877715</span>  -<span class="number">0.38087761</span>    <span class="number">0.21568831</span>]</span><br><span class="line"> [  <span class="number">6.46320807</span>  <span class="number">36.75111647</span>   <span class="number">8.38255336</span> ...   <span class="number">1.912145</span>     <span class="number">1.79468946</span>   -<span class="number">0.70142249</span>]</span><br><span class="line"> [ -<span class="number">7.99030162</span>   <span class="number">2.40438257</span> -<span class="number">11.03006405</span> ...  -<span class="number">0.72188348</span>  -<span class="number">1.15719089</span>   -<span class="number">0.23704277</span>]</span><br><span class="line"> ...</span><br><span class="line"> [  <span class="number">8.61143331</span>   <span class="number">7.70129866</span>   <span class="number">7.95240226</span> ...   <span class="number">0.23971061</span>  -<span class="number">0.78590175</span>   -<span class="number">2.65945606</span>]</span><br><span class="line"> [ <span class="number">84.08621987</span>  <span class="number">20.41873398</span>   <span class="number">8.05410372</span> ...  -<span class="number">1.66893212</span>   <span class="number">0.5042934</span>    <span class="number">3.82546312</span>]</span><br><span class="line"> [-<span class="number">13.95345619</span>   <span class="number">6.64621821</span>  -<span class="number">5.23030367</span> ...  -<span class="number">1.64144758</span>  -<span class="number">3.39233648</span>   -<span class="number">0.31410713</span>]]</span><br><span class="line">降维后的维度：</span><br><span class="line"> (<span class="number">206209</span>, <span class="number">44</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/02/sklearn/3_sklearn%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/02/sklearn/3_sklearn%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/" class="post-title-link" itemprop="url">P3_sklearn特征预处理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-02 20:48:00" itemprop="dateCreated datePublished" datetime="2023-11-02T20:48:00+08:00">2023-11-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-05 13:32:36" itemprop="dateModified" datetime="2023-11-05T13:32:36+08:00">2023-11-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="特征工程-特征预处理"><a href="#特征工程-特征预处理" class="headerlink" title="特征工程-特征预处理"></a>特征工程-特征预处理</h1><ul>
<li>学习目标：<ul>
<li>了解数值型数据、类别型数据特点</li>
<li>应用MinMaxScaler实现对特征数据进行归一化</li>
<li>应用StandardScaler实现对特征数据进行标准化<br/></li>
</ul>
</li>
</ul>
<h3 id="什么是特征预处理："><a href="#什么是特征预处理：" class="headerlink" title="什么是特征预处理："></a>什么是特征预处理：</h3><ul>
<li><p>sklearn官方定义：</p>
<ul>
<li>通过<strong>一些转换函数</strong>将特征数据<strong>转换成更适合算法模型</strong>的特征数据过程<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231103110240.png"><br/></li>
</ul>
</li>
<li><p>包含内容：</p>
<ul>
<li>数值型数据的<strong>无量纲化</strong>：<ul>
<li>归一化</li>
<li>标准化<br/></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="为什么要进行归一化、标准化："><a href="#为什么要进行归一化、标准化：" class="headerlink" title="为什么要进行归一化、标准化："></a>为什么要进行归一化、标准化：</h3><ul>
<li>特征的<strong>单位或大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，同意印象（支配）目标结果</strong>，使得一些算法无法学习到其他的特征<br/></li>
</ul>
<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><p>通过原始的数据进行变化吧数据映射的（默认为[0, 1]之间）</p>
</li>
<li><p>公式<br>$$<br>x’ &#x3D; \frac{x - min}{max &#x3D; min} \qquad  x’’ &#x3D; x’ * (mx - mi) + mi<br>$$</p>
<blockquote>
<p>作用于每一列，max为一列的最大值，min为一列的最小值，那么$x’’$为最终结果，mx, mi分别为指定区间默认xmx为1，mi为0</p>
</blockquote>
</li>
<li><p><strong>API</strong></p>
<ul>
<li>sklearn.preprocessing.MinMaxScaler(feature_range&#x3D;(0,1),…)<ul>
<li>MinMaxScalar.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后形状相同的array</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 归一化演示代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、实例化一个转换器类</span></span><br><span class="line">transfer = MinMaxScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new  = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231104110437.png"></p>
</li>
</ul>
<h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><ul>
<li>归一化的问题：<ul>
<li>因为归一化是有最大值与最小值求出的，容易收到异常点的印象，这种方法鲁棒性较差，只适合传统精确小数据场景。</li>
</ul>
</li>
</ul>
<h3 id="定义：-1"><a href="#定义：-1" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><p>通过对原始数据进行变化吧数据变换到均值为0，标准差为1范围内</p>
<br/>
</li>
<li><p>公式：<br>$$<br>X’ &#x3D; \frac{x - mean}{\sigma}<br>$$</p>
<blockquote>
<p>作用于每一列，$mean$为平均值，$\sigma$为标准差</p>
</blockquote>
</li>
<li><p>对于归一化来说：若果出现了异常点，印象了最大值和最小值，那么结果显然会发生改变。</p>
</li>
<li><p>对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</p>
<br/>
</li>
<li><p><strong>API</strong></p>
<ul>
<li>sklearn.preprocseeing.StandardScaler()<ul>
<li>处理之后，对每列来说，所有数据都聚集在均值为0附近，标准差为1</li>
<li>StandardScaler.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后的形状相同的array<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化演示代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new  = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105110545.png"></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>标准化总结：</strong><br>在已有样本足够多的情况下比较稳定，适合现在嘈杂大数据场景。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/01/sklearn/2_sklearn%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/01/sklearn/2_sklearn%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/" class="post-title-link" itemprop="url">P2_sklearn特征抽取</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-01 10:44:00" itemprop="dateCreated datePublished" datetime="2023-11-01T10:44:00+08:00">2023-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-02 20:50:47" itemprop="dateModified" datetime="2023-11-02T20:50:47+08:00">2023-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="特征工程-数据抽取"><a href="#特征工程-数据抽取" class="headerlink" title="特征工程-数据抽取"></a>特征工程-数据抽取</h2><ul>
<li>特征提取&#x2F;特城抽取定义：将任意数据（如文本或图像）转换为可用于机器学习的数字特征</li>
<li>特征提取的类别：<ul>
<li>字典特征提取（特征离散化）</li>
<li>文本特征提取</li>
<li>图像特征提取（主要在深度学习部分学习）</li>
</ul>
</li>
<li>特征提取api:<ul>
<li>sklearn.feature_extraceion</li>
</ul>
</li>
</ul>
<h3 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h3><ul>
<li><p>作用：对字典数据进行特征值化</p>
</li>
<li><p>sklearn.feature_extraction.DictVectorizer(sparse&#x3D;True, …)</p>
<ul>
<li>DictVectorizer.fit_transform(字典或包含字典的可迭代对象)<ul>
<li>返回值：sparse矩阵</li>
</ul>
</li>
<li>DictVercotizer.inverse_transform(数组或者sparse矩阵)<ul>
<li>返回值：转换之前的数据格式</li>
</ul>
</li>
<li>DictVercotizer.get_feature_names()<ul>
<li>返回值：返回类别名称</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
<ul>
<li>对下面的数据进行特征提取<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">100</span>&#125;,</span><br><span class="line">&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">60</span>&#125;,</span><br><span class="line">&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">30</span>&#125;]</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>流程分析：</p>
<ul>
<li>实例化类：DictVectorizer</li>
<li>调用fit_transform方法输入数据并转换（注意返回格式）</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line">data = [&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">100</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">60</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">30</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = DictVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_trancform()方法</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p>输出：sparse矩阵（稀疏矩阵）<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101154856.png"></p>
<ul>
<li>如何返回一般矩阵：<ul>
<li>初始化DictVectorizer类时方法拥有一个参数 sparse 若不指定，默认 sparse&#x3D;True 使用关键字参数将其指定为False即可返回一般矩阵</li>
</ul>
</li>
</ul>
<p>修改初始化参数后返回的矩阵：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101155556.png"></p>
<ul>
<li>查看特征值：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="文本特征抽取CountVectorizer"><a href="#文本特征抽取CountVectorizer" class="headerlink" title="文本特征抽取CountVectorizer"></a>文本特征抽取CountVectorizer</h3><ul>
<li><p>作用：对文本数据进行特征值化</p>
</li>
<li><p>sklearn.feature_extraction.text.ConuntVectorizer(stop_words&#x3D;[])</p>
<ul>
<li>返回词频矩阵</li>
</ul>
</li>
<li><p>CountVectorizer.fit_transform(包含文本字符串的可迭代对象)</p>
<ul>
<li>返回 sparse 矩阵</li>
</ul>
</li>
<li><p>CountVectorizer.inverse_atransform(数组或者 sparse 矩阵)</p>
<ul>
<li>返回转换之前的数据格式</li>
</ul>
</li>
<li><p>CountVectorizer.get_feature_names()</p>
<ul>
<li>返回单词列表</li>
</ul>
</li>
<li><p>stop_words：停用词，如果需要过滤无用的单词就添加到列表中传入这个参数。</p>
</li>
<li><p>sklearn.feature_extraceion.text.TfidfVectorizer</p>
</li>
<li><p>示例：</p>
<ul>
<li>对以下数据进行特征提取：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&quot;life is short,i like python&quot;</span>,</span><br><span class="line"><span class="string">&quot;Life is too long,i dislike python&quot;</span>]</span><br></pre></td></tr></table></figure>
演示代码：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;life is short,i like python&quot;</span>,<span class="string">&quot;Life is too long,i dislike python&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = CountVectorizer()</span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
默认输入 sparse 稀疏数组<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data_new：</span><br><span class="line">   (<span class="number">0</span>, <span class="number">2</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">1</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">6</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">3</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">5</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">2</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">1</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">5</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">7</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">4</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">0</span>)	<span class="number">1</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>CountVectorizer转换器没有 sparse 参数，若要输出一般数组，需要使用到 sparse 对象的toarray()方法。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 顺便显示特征名：</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new.toarray())</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">特征名字：</span><br><span class="line"> [<span class="string">&#x27;dislike&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;life&#x27;</span>, <span class="string">&#x27;like&#x27;</span>, <span class="string">&#x27;long&#x27;</span>, <span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;short&#x27;</span>, <span class="string">&#x27;too&#x27;</span>]</span><br><span class="line">data_new：</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure></li>
<li><p>尝试使用中文句子：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101185826.png"></p>
</li>
<li><p>可以看到转换器把整个句子当做了特征，这显然不是我们想要的效果。</p>
</li>
<li><p>原因是因为CountVertorizer转换器本身是适配英文的，英文的每个单词之间是自带空格的，如果要正确为中文句子提取特征，需要添加空格。<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101191230.png"></p>
</li>
</ul>
<h3 id="CountVectorizer中文文本提取"><a href="#CountVectorizer中文文本提取" class="headerlink" title="CountVectorizer中文文本提取"></a>CountVectorizer中文文本提取</h3><ul>
<li>上面使用中文发现需要手动对词语进行空格隔开，接下要做的事就是自动化这个步骤</li>
<li>借助 jieba 库先将中文文本的词语按词分开，然后再使用转换器提取特征。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人都不要放弃今天。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我们看到的从很远的星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span> ]</span><br><span class="line"></span><br><span class="line">data_new = [<span class="string">&#x27; &#x27;</span>.join(jieba.cut(i)) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = CountVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_final = transfer.fit_transform(data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_final.toarray())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102202921.png"></li>
</ul>
<h3 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h3><ul>
<li><p>什么是关键词？</p>
<ul>
<li>在某一个类别的文章中，出现的次数很多，但是在其他类别的文章中出现很少</li>
<li>关键词是区分文章类别的关键信息<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102092030.png"></li>
</ul>
</li>
<li><p>TF-IDF</p>
<ul>
<li>TF-IDF的主要是想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的区分类别能力，适合用来分类。</li>
<li>TF-IDF作用：用以评估一个词对于一个文件集或一个语料库中的其中一份文件的重要程度。</li>
</ul>
</li>
<li><p>公式</p>
<ul>
<li>词频（term frequency, tf）指的是某一个给定的词语在该文件中出现的频率</li>
<li>逆向文档频率（inverse document frequency, idf）是一个词语普遍重性的程度。某一特定词语的idf，可以由文件总数目除以包含该词语 的文件的树木，再将得到的商取以10为底的对数得到。<br>$$<br>tfidf_{i,j} &#x3D; tf_{i,j} \times idf_i<br>$$</li>
<li>最终得出结果可以理解为重要程度</li>
</ul>
</li>
<li><p>计算tf-idf例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">有两个词“经济”与“非常”</span><br><span class="line"><span class="number">1000</span>篇文章 - 语料库</span><br><span class="line"><span class="number">100</span>篇文章 - 包含“非常”</span><br><span class="line"><span class="number">10</span>篇文章 - 包含“经济”</span><br><span class="line"></span><br><span class="line">两篇文章：</span><br><span class="line">文章A(<span class="number">100</span>词)：出现<span class="number">10</span>次“经济”</span><br><span class="line">    tf: <span class="number">10</span>/<span class="number">100</span> = <span class="number">0.1</span></span><br><span class="line">    idf: lg <span class="number">1000</span>/<span class="number">10</span> = <span class="number">2</span></span><br><span class="line">文章B(<span class="number">100</span>词)：出现<span class="number">10</span>次“非常”</span><br><span class="line">    tf: <span class="number">10</span>/<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line">    idf: lg <span class="number">1000</span>/<span class="number">100</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">“经济”tf-idf：<span class="number">0.2</span></span><br><span class="line">“非常”tf-idf：<span class="number">0.1</span></span><br></pre></td></tr></table></figure></li>
<li><p>API</p>
<ul>
<li>sklearn.feature_extraction.text.TfidfVectorizer(stop_words&#x3D;None,…)</li>
<li>返回词的权重矩阵<ul>
<li>TfidfVectorizer.fit_transform(文本或包含文本字符串的可迭代对象)<ul>
<li>返回 sparse 矩阵</li>
</ul>
</li>
<li>TfidfVectorizer.inverse_transform(array数组或者sparse矩阵)<ul>
<li>返回转换之前的数据格式</li>
</ul>
</li>
<li>TfidfVectorizer.get_feature_names()<ul>
<li>返回单词列表</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人都不要放弃今天。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我们看到的从很远的星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span> ]</span><br><span class="line"></span><br><span class="line">data_new = [<span class="string">&#x27; &#x27;</span>.join(jieba.cut(i)) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化TfidfVectorizer</span></span><br><span class="line">transfer = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_final = transfer.fit_transform(data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_final.toarray())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102202952.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/31/sklearn/1_%E8%8E%B7%E5%8F%96sklearn%E6%95%B0%E6%8D%AE%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/31/sklearn/1_%E8%8E%B7%E5%8F%96sklearn%E6%95%B0%E6%8D%AE%E9%9B%86/" class="post-title-link" itemprop="url">P1_获取sklearn数据集</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-31 19:31:00" itemprop="dateCreated datePublished" datetime="2023-10-31T19:31:00+08:00">2023-10-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-01 10:07:54" itemprop="dateModified" datetime="2023-11-01T10:07:54+08:00">2023-11-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="如何获取数据集"><a href="#如何获取数据集" class="headerlink" title="如何获取数据集"></a>如何获取数据集</h2><ul>
<li>使用方法库sklearn.dataset<ul>
<li>加载获取流行数据集（两种方法）</li>
<li><strong>datasets.load_*()</strong><ul>
<li>获取小规模数据集，数据包含在datasets里</li>
</ul>
</li>
<li><strong>satasets.fetch_*(data_home&#x3D;None)</strong><ul>
<li>获取大规模数据集，需要从网络上下载，函数的第一哥参数是data_home，表示数据集下载的目录，默认是~&#x2F;scikit_learn_data&#x2F;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="获取sklearn小数据集"><a href="#获取sklearn小数据集" class="headerlink" title="获取sklearn小数据集"></a>获取sklearn小数据集</h2><ul>
<li>sklearn.datasets.load_iris()<ul>
<li>加载并返回鸢尾花数据集<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="right">数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">类别</td>
<td align="right">3</td>
</tr>
<tr>
<td align="left">特征</td>
<td align="right">4</td>
</tr>
<tr>
<td align="left">样本数量</td>
<td align="right">150</td>
</tr>
<tr>
<td align="left">每个类别数量</td>
<td align="right">50</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li>sklearn.datasets.load_boston()<ul>
<li>加载返回波士顿放假数据集<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="right">数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">目标类型</td>
<td align="right">5-50</td>
</tr>
<tr>
<td align="left">特征</td>
<td align="right">13</td>
</tr>
<tr>
<td align="left">样本数量</td>
<td align="right">506</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h2 id="获取sklearn大数据集"><a href="#获取sklearn大数据集" class="headerlink" title="获取sklearn大数据集"></a>获取sklearn大数据集</h2><ul>
<li>sklearn.datasets.fetch_20newsgroups(data_home&#x3D;None, subset&#x3D;’train’)<ul>
<li>subset：’train’或者’test’,’all’，可选，选择需要加载的数据集</li>
<li>数据集的“训练”，测试集的“测试”，两者的“全部”</li>
</ul>
</li>
</ul>
<h2 id="sklearn数据集的使用"><a href="#sklearn数据集的使用" class="headerlink" title="sklearn数据集的使用"></a>sklearn数据集的使用</h2><ul>
<li><p>以鸢尾花数据集为例：</p>
</li>
<li><p>特征值4个：花瓣、花萼的长度、宽度</p>
</li>
<li><p>目标值3个：setosa, vericolor, virginica</p>
</li>
<li><p><strong>sklearn数据集返回值介绍：</strong></p>
<ul>
<li>load和fetch返回的数据类型为dataset.base.Bunch（字典格式）<ul>
<li>data：特征数据数组，是 [n_samples * n_features]的二维ndarray数组</li>
<li>target：标签数组，是 n_samples 的以为ndarray数组</li>
<li>DESCR：数据描述</li>
<li>feature_names：特征名，新闻数据、手写数字、回归数据集没有</li>
<li>target_names：标签名</li>
</ul>
</li>
<li>数据集的索引方法：<ul>
<li>dict[“key”] &#x3D; values</li>
<li>bunch.key &#x3D; values</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn加载数据集演示代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;鸢尾花数据集：\n&quot;</span>, iris)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看数据描述：\n&quot;</span>, iris[<span class="string">&quot;DESCR&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值的名字：\n&quot;</span>, iris.feature_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值：\n&quot;</span>, iris.data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值shape：\n&quot;</span>, iris.data.shape)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>思考：拿到的数据是否全部都用来训练第一个模型？</strong></p>
<ul>
<li>如果数据全部用来训练模型，就没有数据用来测试。</li>
<li>获取到数据后可以划分为训练集与测试集。</li>
<li>一部分数据用于训练模型，一部分数据用来验证模型的准确度。</li>
</ul>
</blockquote>
<h2 id="数据集的划分"><a href="#数据集的划分" class="headerlink" title="数据集的划分"></a>数据集的划分</h2><ul>
<li><p>机器学习一般分分为两个部分：</p>
<ul>
<li>训练数据：用于训练，构建模型</li>
<li>测试数据：在模型验证时使用，，用于评估模型是否有效</li>
</ul>
</li>
<li><p>划分比例：</p>
<ul>
<li>训练集：70%，80%，75%</li>
<li>测试集：30%，20%，30%</li>
</ul>
</li>
<li><p><strong>数据集划分api：</strong></p>
<ul>
<li>sklearn.model_selection.train_test_split(arrays, *iptions)</li>
<li>参数列表：<ul>
<li>x 数据集的特征值</li>
<li>y 数据集的标签值</li>
<li>test_size 测试集的大小</li>
<li>random_state 随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。</li>
</ul>
</li>
<li>返回值：<ul>
<li>训练集特征值，测试集特征值，训练集目标值，测试集目标值。</li>
<li>一般命名：x_train, x_test, y_train, y_test<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集划分演示代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection.train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.traget, test_size=<span class="number">0.2</span>, random_state=<span class="number">114514</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;数据集的特征值：\n&#x27;</span>, iris.data, iris.data.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;划分后训练集的特征值：\n&#x27;</span>, x_train, x_train.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<div align="center">
   <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101093726.png"  height=130><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101093841.png" height=130>
</div>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="porridge42"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">porridge42</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">166</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/porridge42" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;porridge42" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">porridge42</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
