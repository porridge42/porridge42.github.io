<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="NanBlog 稀饭目标">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="NanBlog 稀饭目标">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="porridge42">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>NanBlog 稀饭目标</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">NanBlog 稀饭目标</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-fa fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/09/sklearn/6_KNN%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/09/sklearn/6_KNN%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">P6_KNN算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-09 09:50:00" itemprop="dateCreated datePublished" datetime="2023-11-09T09:50:00+08:00">2023-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-16 20:37:52" itemprop="dateModified" datetime="2023-11-16T20:37:52+08:00">2023-11-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="K-近邻算法学习目标"><a href="#K-近邻算法学习目标" class="headerlink" title="K-近邻算法学习目标"></a>K-近邻算法学习目标</h2><ul>
<li>学习目标：<ul>
<li>K-近邻算法的距离公式</li>
<li>K-近邻算饭的超参数K值以及取值问题</li>
<li>K-近邻算法的优缺点</li>
<li>应用KNeighbrosClassifier实现分类</li>
<li>了解分类算法的评估标准准确率</li>
</ul>
</li>
<li>应用：<ul>
<li>鸢尾花数据集预测</li>
<li>Facebook签到位置预测</li>
</ul>
</li>
<li>内容：<ul>
<li>什么是K-近邻算法</li>
<li>K-近邻算法API</li>
<li>案例：鸢尾花种类预测</li>
<li>K-近邻总结</li>
</ul>
</li>
</ul>
<h2 id="K-近邻算法-KNN-原理"><a href="#K-近邻算法-KNN-原理" class="headerlink" title="K-近邻算法(KNN)原理"></a>K-近邻算法(KNN)原理</h2><p>K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法，总体来说KNN算法是相对比较容易理解的算法</p>
<ul>
<li>定义<ul>
<li>若果一个样本在特征空间中的k个最相似（即特征空间中最邻近）的样本中大多数属于某一个类别，则该样本也属于这个类别。</li>
</ul>
</li>
<li>距离公式<ul>
<li>连个样本的距离可以通过如下公式计算，又叫欧氏距离</li>
<li>比如说：a(a1,a2,a3),b(b1,b2,b3)<br>$$<br>\sqrt{(a1-b1)^2+(a2-b2)^2+(a3-b3)^2}<br>$$</li>
</ul>
</li>
</ul>
<h2 id="K-近邻算法API"><a href="#K-近邻算法API" class="headerlink" title="K-近邻算法API"></a>K-近邻算法API</h2><ul>
<li>sklearn.neighbors.KNeighbrosClassifier(n_neighbors&#x3D;5, algorithm&#x3D;’auto’)<ul>
<li>n_neighbors：int,可选（默认为&#x3D;5），k_neighbors查询默认使用的邻居数</li>
<li>algorithm：{‘auto, ‘ball_ress, ‘kd_tree’, ‘brute’},可选用与计算最邻近邻居的算法：’ball_tree’将会使用BallTree,’kd_tree’将使用KDTree。’auto’将尝试根据传递给fit方法的值来决定最合适的算法。（不同实现方式影响效率）</li>
</ul>
</li>
</ul>
<h2 id="案例：鸢尾花种类预测"><a href="#案例：鸢尾花种类预测" class="headerlink" title="案例：鸢尾花种类预测"></a>案例：鸢尾花种类预测</h2><ul>
<li>数据集简介：<ul>
<li>示例数量：150（三个类各有50个）</li>
<li>属性数量：4（数值型，数值型，帮助预测的属性和类）</li>
<li><strong>Attribute Information:</strong><ul>
<li>sepal length 萼片长度（厘米）</li>
<li>sepal width 萼片宽度（厘米）</li>
<li>petal length 花瓣长度（厘米）</li>
<li>petal width 花瓣宽度（厘米）<ul>
<li><strong>class:</strong></li>
<li>Iris-Setosa 山鸢尾</li>
<li>Iris-Versicolour 变色鸢尾</li>
<li>Iris-Virginica 维吉尼亚鸢尾</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>流程规划：</strong></li>
</ul>
<ol>
<li>获取数据</li>
<li>划分数据集</li>
<li>特征工程-标准化</li>
<li>KNN算法预估器</li>
<li>模型评估<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用knn算法对鸢尾花进行分类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1) 获取数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">114514</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 特征工程：标准化</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) KNN算法预估器</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5) 模型评估</span></span><br><span class="line"><span class="comment"># 方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;直接比对真实值和预测值：\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2：计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, score)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231114144536.png"></li>
</ol>
<h2 id="KNN算法总结："><a href="#KNN算法总结：" class="headerlink" title="KNN算法总结："></a>KNN算法总结：</h2><ul>
<li>优点：<ul>
<li>简单，易于理解，易于实现，无需训练</li>
</ul>
</li>
<li>缺点：<ul>
<li>懒惰算法，对测试样本分类时的计算量打，内存开销大</li>
<li>必须指定K值，K值选择不当则分类精度不能保证</li>
</ul>
</li>
<li>使用场景：小数据场景，几千~几万样本具体场景具体业务与测试</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/07/sklearn/5_sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/07/sklearn/5_sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/" class="post-title-link" itemprop="url">P5_sklearn转换器和估计器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-07 19:54:00" itemprop="dateCreated datePublished" datetime="2023-11-07T19:54:00+08:00">2023-11-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-09 09:48:57" itemprop="dateModified" datetime="2023-11-09T09:48:57+08:00">2023-11-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分类算法-sklearn转换器与估计器"><a href="#分类算法-sklearn转换器与估计器" class="headerlink" title="分类算法-sklearn转换器与估计器"></a>分类算法-sklearn转换器与估计器</h1><h2 id="转换器"><a href="#转换器" class="headerlink" title="转换器"></a>转换器</h2><ul>
<li>回忆一下之前的特征工程步骤：<ul>
<li>1、实例化（实例化的是一个转换器类(Transformer)）</li>
<li>2、调用fit_transform（对于文档建立分类词频矩阵，不能同时调用）</li>
</ul>
</li>
<li>我们把特诊工程的结接口称之为转换器，其中转换器调用有这么几种形式<ul>
<li>fit_transform</li>
<li>fit</li>
<li>transform</li>
</ul>
</li>
</ul>
<h2 id="估计器（sklearn机器学习算法的实现）"><a href="#估计器（sklearn机器学习算法的实现）" class="headerlink" title="估计器（sklearn机器学习算法的实现）"></a>估计器（sklearn机器学习算法的实现）</h2><ul>
<li><p>在sklearn中，估计器(estimator)是一个重要的角色，是一类实现了算法的API</p>
<ul>
<li>1、用于分类的估计器：<ul>
<li>sklearn.neighbors k-近邻算法</li>
<li>sklearn.naive_bayes 贝叶斯</li>
<li>sklearn.linear_model.LogisticRegression 逻辑回归</li>
<li>sklearn.tree 决策树与随机森林</li>
</ul>
</li>
<li>2、用于回归的估计器：<ul>
<li>sklearn.linear_model.LinearRegression 线型回归</li>
<li>sklearn.linear_model.Ridge 岭回归</li>
</ul>
</li>
<li>3、用于无监督学习的估计器<ul>
<li>sklearn.cluster.KMeans 聚类<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/II4LU%7E7VRFUYWLNIXAJAV5F.png"></li>
</ul>
</li>
</ul>
</li>
<li><p>估计器的使用：</p>
<ul>
<li>1、实例化一个estimator</li>
<li>2、estimator.fit(x_tran, y_tran) 计算<ul>
<li>–调用完毕，模型生成</li>
</ul>
</li>
<li>3、模型评估：<ol>
<li>直接比对真实值和预测值<br>y_predict &#x3D; estimator.predict(x_test)<br>y_test &#x3D;&#x3D; y_predict </li>
<li>计算准确率<br>estimator.score(x_test, y_test)</li>
</ol>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/05/sklearn/4_sklearn%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/05/sklearn/4_sklearn%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/" class="post-title-link" itemprop="url">P4_sklearn特征降维</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-05 11:05:00" itemprop="dateCreated datePublished" datetime="2023-11-05T11:05:00+08:00">2023-11-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-07 19:50:49" itemprop="dateModified" datetime="2023-11-07T19:50:49+08:00">2023-11-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="特征工程-降维"><a href="#特征工程-降维" class="headerlink" title="特征工程-降维"></a>特征工程-降维</h1><ul>
<li>学习目标：<ul>
<li>引用VarianceThreshold实现删除低方差特征</li>
<li>了解相关系数的特点和计算</li>
<li>应用相关系数实现特征选择</li>
</ul>
</li>
</ul>
<h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><strong>降维</strong>是只在某些限定条件下。<strong>降低随机变量（特征）个数</strong>，得到一组<strong>不相关</strong>的主变量的过程.</li>
</ul>
<p> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105130621.png"></p>
<ul>
<li>相关特征（什么是相关）<ul>
<li>例如：相对湿度与降雨量之间的相关.</li>
<li>等等…<blockquote>
<p>正是因为在训练的时候录，我们都是使用特征进行学习。如果特征本上存在问题或者特征之间相关性比较强，对算法学习预测会影响比较大</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="降维的两种方式："><a href="#降维的两种方式：" class="headerlink" title="降维的两种方式："></a>降维的两种方式：</h3><ul>
<li>特征选择</li>
<li>主成分分析（可以理解为一种特征提取的方式）<br/></li>
</ul>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="什么是特征选择"><a href="#什么是特征选择" class="headerlink" title="什么是特征选择"></a>什么是特征选择</h3><ul>
<li><p>定义： 数据中包含<strong>冗余或相关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出特征</strong>。<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105132916.png"></p>
<blockquote>
<p>如果在此处添加一个特征“知否有爪子”或者“是否有眼睛”类似的特征，明显就是属于冗余特征</p>
</blockquote>
</li>
<li><p>如何使用数学方法找出并去除数据中的冗余&#x2F;相关特征？</p>
</li>
<li><p><strong>方法：</strong></p>
<ul>
<li>Fillter(过滤式)：主要探究特征本身特点、特征与特征和目标之间关联<ul>
<li>方差选择法：低方差特征过滤</li>
<li>相关系数</li>
</ul>
</li>
<li>Embedded(嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul>
<li>决策树：信息熵、信息增益</li>
<li>正则化：L1、L2</li>
<li>深度学习：卷积等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="过滤式"><a href="#过滤式" class="headerlink" title="过滤式"></a>过滤式</h3><h4 id="方差选择法："><a href="#方差选择法：" class="headerlink" title="方差选择法："></a>方差选择法：</h4><ul>
<li><p>删除低方差的一些特征，在结合方差的大小来考虑这个方式的角度。</p>
<ul>
<li>特征方差小：某个特征大多样本的值都比较相近</li>
<li>特征方差大：某个特征很多样本呢的值都有差别</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
<ul>
<li>sklearn.feature_selection.VarianceThreshold(thrshold &#x3D; 0.0)<ul>
<li>删除所有低方差特征</li>
<li>Variance.fit_transform(ndrray[n_samples, n_features])</li>
<li>返回值：训练集相差异低于threshold的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。<br/></li>
</ul>
</li>
</ul>
</li>
<li><p>数据计算<br>我们对某些股票的指标特征之间进行一个筛选，数据在”factor_returns.csv”文件中，除去’index’,’data’,’return’列不考虑（这些类型不匹配，也不是所需要的指标）<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203605.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、导入数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./factor_returns.csv&#x27;</span>)</span><br><span class="line">data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data：\n&quot;</span>, data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、初始化VarianceThreshold并制定方差阈值</span></span><br><span class="line">transfer = VarianceThreshold(threshold = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, pd.DataFrame(data_new))</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203744.png"><br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105203807.png"></p>
</li>
</ul>
<h4 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h4><ul>
<li><p>皮尔逊相关系数（Pearson Correlation Coefficient）</p>
<ul>
<li>反应变量之间相关关系密切程度的统计指标</li>
</ul>
</li>
<li><p>公式<br>$$<br>r &#x3D; \frac{n\Sigma xy - \Sigma x \Sigma y}<br>{\sqrt{n\Sigma x^2 - (\Sigma x)^2}\sqrt{n\Sigma y^2 - (\Sigma y)^2}}<br>$$<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106092011.png"><br>&#x3D; 0.9942<br><strong>所以我们最终得出结论是广告投入费与月平均销售额之间有高度的正相关关系。</strong></p>
<br/>
</li>
<li><p><strong>特点：</strong></p>
</li>
<li><p>相关系数的值介于$-1$与$1$之间，即$-1\le r\le 1$。其性质如下：</p>
<ul>
<li>当$r&gt;0$时，表示两变量正相关，$r&lt;0$时，两变量为负相关</li>
<li>当$0&lt;|r|&lt;1$时,表示两变量为完全相关，当$r&#x3D;0$时，表示两变量间无相关关系</li>
<li>当$0&lt;|r|&lt;1$时，表示两变量存在一定程度的相关。且$|r|$越接近1，两变量间线性关系月密切；$|r|$越接近与$0$，表示两变量的线性相关越弱</li>
<li>一般可按三级划分：$|r|&lt;0.4$为低度相关；$0.4\le |r|&lt;0.7$为显著性相关；$0.7\le |r|&lt;1$为高度线型相关</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
<ul>
<li>from scipu.stats import pearsonr<ul>
<li>x：(N,) array_like</li>
<li>y：(N,) array_like</li>
<li>返回值：Pearson相关系数<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./factor_returns.csv&#x27;</span>)</span><br><span class="line">data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">transfer = VarianceThreshold(threshold = <span class="number">10</span>)</span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算两个变量之间的相关系数</span></span><br><span class="line">r1 = pearsonr(data[<span class="string">&quot;pe_ratio&quot;</span>], data[<span class="string">&quot;pb_ratio&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pe_ratio与pb_ratio之间的相关系数：\n&quot;</span>, r1)</span><br><span class="line">r2 = pearsonr(data[<span class="string">&quot;revenue&quot;</span>], data[<span class="string">&quot;total_expense&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;revenue与total_expense之间的相关系数：\n&quot;</span>, r2)</span><br></pre></td></tr></table></figure>
输出：<br>pe_ratio与pb_ratio之间的相关系数：<br> (-0.004389322779936285, 0.8327205496564927)<br>revenue与total_expense之间的相关系数：<br> (0.99584504131361, 0.0)</li>
</ul>
</li>
</ul>
</li>
<li><p>当两个特征变量相关型很高时如何操作：</p>
<ul>
<li>选取其中一个</li>
<li>加权求和</li>
<li>主成分分析</li>
</ul>
</li>
</ul>
<h4 id="主成分分析："><a href="#主成分分析：" class="headerlink" title="主成分分析："></a>主成分分析：</h4><ul>
<li><p>什么是主成分分析(PCA)：</p>
<ul>
<li>定义：<strong>高维数据转换为低维数据的过程</strong>，在此过程中可能会<strong>舍弃原有数据、创造新的变量</strong></li>
<li>作用：<strong>是数据维数压缩，尽可能降低元数据的维数（复杂度），损失少量的信息。</strong></li>
<li>应用：回归分析或者聚类分析当中</li>
<li>原理简介：<br>假设对于给定的5个点，数据如下：<br><code>(-1, -2), (-1, 0), (0, 0), (2, 1), (0, 1)</code><br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106155048.png"><br>要求将这个二维的数据简成一维，并算是少量的信息<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106155220.png"><br><strong>找到一个合适的直线，通过一个矩阵运算得出主成分分析的结果</strong><br>$$<br>Y&#x3D;(\frac{1}{\sqrt{2}}\enspace\frac{1}{\sqrt{2}})<br>\begin{pmatrix}-1&amp;-1&amp;0&amp;2&amp;0\newline-2&amp;0&amp;0&amp;1&amp;1\end{pmatrix}<br>&#x3D;(\frac{-3}{\sqrt{2}}\enspace\frac{-1}{\sqrt{2}}\enspace 0\enspace\frac{3}{\sqrt{2}}\enspace\frac{-1}{\sqrt{2}})<br>$$</li>
</ul>
</li>
<li><p><strong>API：</strong></p>
</li>
<li><p>sklearn.decomposition.PCA(n_components&#x3D;None)</p>
<ul>
<li>将数据分解为较低维数空间</li>
<li>n_components：<ul>
<li>小数：表示保留百分之多少的信息</li>
<li>整数：减少到多少特征</li>
</ul>
</li>
<li>PCA.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后指定维度的array</li>
</ul>
</li>
<li><p>计算示例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],</span><br><span class="line">[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231106195504.png"></p>
</li>
</ul>
<h2 id="案例：探究用户对物品分类的喜好细分降维"><a href="#案例：探究用户对物品分类的喜好细分降维" class="headerlink" title="案例：探究用户对物品分类的喜好细分降维"></a>案例：探究用户对物品分类的喜好细分降维</h2><ul>
<li>数据如下：<ul>
<li>order_products_prior.csv：订单与商品信息<ul>
<li>字段：<strong>order_id, product_id,</strong> add_to_cart_order, reordered</li>
</ul>
</li>
<li>products.csv：商品信息<ul>
<li>字段：<strong>product_id,</strong> product_name, aisle_id, department_id</li>
</ul>
</li>
<li>orders.csv：用户的订单信息<ul>
<li>字段：<strong>order_id, user_id,</strong> eval_set, order_number, …</li>
</ul>
</li>
<li>aisles.csv：商品所属具体物品类别<ul>
<li>字段：<strong>aisle_id, aisle</strong><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">order_products = pd.read_csv(<span class="string">&quot;./instacart/order_products__prior.csv&quot;</span>)</span><br><span class="line">products = pd.read_csv(<span class="string">&quot;./instacart/products.csv&quot;</span>)</span><br><span class="line">orders = pd.read_csv(<span class="string">&quot;./instacart/orders.csv&quot;</span>)</span><br><span class="line">aisles = pd.read_csv(<span class="string">&quot;./instacart/aisles.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、合并表</span></span><br><span class="line">tab1 = pd.merge(aisles, products, on=[<span class="string">&quot;aisle_id&quot;</span>, <span class="string">&quot;aisle_id&quot;</span>])</span><br><span class="line">tab2 = pd.merge(tab1, order_products, on=[<span class="string">&quot;product_id&quot;</span>, <span class="string">&quot;product_id&quot;</span>])</span><br><span class="line">tab3 = pd.merge(tab2, orders, on=[<span class="string">&quot;order_id&quot;</span>, <span class="string">&quot;order_id&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;合并后的原始数据：\n&quot;</span>, tab3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、找到user_id和aisle之间的关系</span></span><br><span class="line">table = pd.crosstab(tab3[<span class="string">&quot;user_id&quot;</span>], tab3[<span class="string">&quot;aisle&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;user_id与aisle的交叉表：\n&quot;</span>, table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、PCA降维</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">data_new = transfer.fit_transform(table)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的数据：\n&quot;</span>, data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;降维后的维度：\n&quot;</span>, data_new.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><strong>输出：</strong><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">合并后的原始数据：</span><br><span class="line">           aisle_id                       aisle  product_id  \</span><br><span class="line"><span class="number">0</span>                <span class="number">1</span>       prepared soups salads         <span class="number">209</span>   </span><br><span class="line"><span class="number">1</span>                <span class="number">1</span>       prepared soups salads       <span class="number">22853</span>   </span><br><span class="line"><span class="number">2</span>                <span class="number">4</span>               instant foods       <span class="number">12087</span>   </span><br><span class="line"><span class="number">3</span>                <span class="number">4</span>               instant foods       <span class="number">47570</span>   </span><br><span class="line"><span class="number">4</span>               <span class="number">13</span>              prepared meals       <span class="number">10089</span>   </span><br><span class="line"><span class="meta">... </span>           ...                         ...         ...   </span><br><span class="line"><span class="number">32434484</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">47713</span>   </span><br><span class="line"><span class="number">32434485</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434486</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434487</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"><span class="number">32434488</span>       <span class="number">134</span>  specialty wines champagnes       <span class="number">49562</span>   </span><br><span class="line"></span><br><span class="line">                                      product_name  department_id  order_id  \</span><br><span class="line"><span class="number">0</span>                              Italian Pasta Salad             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">1</span>                                Pesto Pasta Salad             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">2</span>                 Chicken Flavor Ramen Noodle Soup              <span class="number">9</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">3</span>         Original Flavor Macaroni &amp; Cheese Dinner              <span class="number">9</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="number">4</span>                                           Dolmas             <span class="number">20</span>     <span class="number">94246</span>   </span><br><span class="line"><span class="meta">... </span>                                           ...            ...       ...   </span><br><span class="line"><span class="number">32434484</span>                            Sparkling Rose              <span class="number">5</span>   <span class="number">3014872</span>   </span><br><span class="line"><span class="number">32434485</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>     <span class="number">34570</span>   </span><br><span class="line"><span class="number">32434486</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>    <span class="number">250923</span>   </span><br><span class="line"><span class="number">32434487</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>   <span class="number">1319402</span>   </span><br><span class="line"><span class="number">32434488</span>             Blanc De Noirs Sparkling Wine              <span class="number">5</span>   <span class="number">2298986</span>   </span><br><span class="line"></span><br><span class="line">          add_to_cart_order  reordered  user_id eval_set  order_number  \</span><br><span class="line"><span class="number">0</span>                         <span class="number">5</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">1</span>                         <span class="number">4</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">2</span>                        <span class="number">15</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">3</span>                        <span class="number">14</span>          <span class="number">1</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="number">4</span>                        <span class="number">25</span>          <span class="number">0</span>   <span class="number">114082</span>    prior            <span class="number">26</span>   </span><br><span class="line"><span class="meta">... </span>                    ...        ...      ...      ...           ...   </span><br><span class="line"><span class="number">32434484</span>                  <span class="number">1</span>          <span class="number">0</span>    <span class="number">63218</span>    prior             <span class="number">1</span>   </span><br><span class="line"><span class="number">32434485</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">37901</span>    prior            <span class="number">13</span>   </span><br><span class="line"><span class="number">32434486</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">26431</span>    prior            <span class="number">27</span>   </span><br><span class="line"><span class="number">32434487</span>                  <span class="number">1</span>          <span class="number">1</span>    <span class="number">26431</span>    prior            <span class="number">34</span>   </span><br><span class="line"><span class="number">32434488</span>                  <span class="number">1</span>          <span class="number">0</span>    <span class="number">37901</span>    prior             <span class="number">9</span>   </span><br><span class="line"></span><br><span class="line">          order_dow  order_hour_of_day  days_since_prior_order  </span><br><span class="line"><span class="number">0</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">1</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">2</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">3</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="number">4</span>                 <span class="number">0</span>                 <span class="number">20</span>                     <span class="number">1.0</span>  </span><br><span class="line"><span class="meta">... </span>            ...                ...                     ...  </span><br><span class="line"><span class="number">32434484</span>          <span class="number">1</span>                 <span class="number">14</span>                     NaN  </span><br><span class="line"><span class="number">32434485</span>          <span class="number">3</span>                  <span class="number">9</span>                    <span class="number">13.0</span>  </span><br><span class="line"><span class="number">32434486</span>          <span class="number">5</span>                 <span class="number">11</span>                    <span class="number">10.0</span>  </span><br><span class="line"><span class="number">32434487</span>          <span class="number">2</span>                 <span class="number">14</span>                     <span class="number">7.0</span>  </span><br><span class="line"><span class="number">32434488</span>          <span class="number">2</span>                 <span class="number">11</span>                    <span class="number">13.0</span>  </span><br><span class="line"></span><br><span class="line">[<span class="number">32434489</span> rows x <span class="number">14</span> columns]</span><br><span class="line">user_id与aisle的交叉表：</span><br><span class="line"> aisle    air fresheners candles  asian foods  baby accessories  \</span><br><span class="line">user_id                                                          </span><br><span class="line"><span class="number">1</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                             <span class="number">0</span>            <span class="number">3</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                             <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                             <span class="number">0</span>            <span class="number">2</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                        ...          ...               ...   </span><br><span class="line"><span class="number">206205</span>                        <span class="number">0</span>            <span class="number">0</span>                 <span class="number">1</span>   </span><br><span class="line"><span class="number">206206</span>                        <span class="number">0</span>            <span class="number">4</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                        <span class="number">0</span>            <span class="number">0</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                        <span class="number">0</span>            <span class="number">3</span>                 <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                        <span class="number">0</span>            <span class="number">1</span>                 <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    baby bath body care  baby food formula  bakery desserts  \</span><br><span class="line">user_id                                                            </span><br><span class="line"><span class="number">1</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                          <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                     ...                ...              ...   </span><br><span class="line"><span class="number">206205</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                     <span class="number">0</span>                  <span class="number">1</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                     <span class="number">0</span>                  <span class="number">3</span>                <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                     <span class="number">0</span>                  <span class="number">0</span>                <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    baking ingredients  baking supplies decor  beauty  beers coolers  \</span><br><span class="line">user_id                                                                     </span><br><span class="line"><span class="number">1</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                         <span class="number">2</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                         <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                    ...                    ...     ...            ...   </span><br><span class="line"><span class="number">206205</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                    <span class="number">4</span>                      <span class="number">1</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                    <span class="number">4</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                    <span class="number">0</span>                      <span class="number">0</span>       <span class="number">0</span>              <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    ...  spreads  tea  tofu meat alternatives  tortillas flat bread  \</span><br><span class="line">user_id  ...                                                               </span><br><span class="line"><span class="number">1</span>        ...        <span class="number">1</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>        ...        <span class="number">3</span>    <span class="number">1</span>                       <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>        ...        <span class="number">4</span>    <span class="number">1</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>        ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">1</span>   </span><br><span class="line"><span class="number">5</span>        ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>     ...      ...  ...                     ...                   ...   </span><br><span class="line"><span class="number">206205</span>   ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>   ...        <span class="number">1</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>   ...        <span class="number">3</span>    <span class="number">4</span>                       <span class="number">0</span>                     <span class="number">2</span>   </span><br><span class="line"><span class="number">206208</span>   ...        <span class="number">5</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">7</span>   </span><br><span class="line"><span class="number">206209</span>   ...        <span class="number">0</span>    <span class="number">0</span>                       <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    trail mix snack mix  trash bags liners  vitamins supplements  \</span><br><span class="line">user_id                                                                 </span><br><span class="line"><span class="number">1</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">2</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">4</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">5</span>                          <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="meta">... </span>                     ...                ...                   ...   </span><br><span class="line"><span class="number">206205</span>                     <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206206</span>                     <span class="number">0</span>                  <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206207</span>                     <span class="number">1</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206208</span>                     <span class="number">0</span>                  <span class="number">0</span>                     <span class="number">0</span>   </span><br><span class="line"><span class="number">206209</span>                     <span class="number">0</span>                  <span class="number">1</span>                     <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">aisle    water seltzer sparkling water  white wines  yogurt  </span><br><span class="line">user_id                                                      </span><br><span class="line"><span class="number">1</span>                                    <span class="number">0</span>            <span class="number">0</span>       <span class="number">1</span>  </span><br><span class="line"><span class="number">2</span>                                    <span class="number">2</span>            <span class="number">0</span>      <span class="number">42</span>  </span><br><span class="line"><span class="number">3</span>                                    <span class="number">2</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">4</span>                                    <span class="number">1</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">5</span>                                    <span class="number">0</span>            <span class="number">0</span>       <span class="number">3</span>  </span><br><span class="line"><span class="meta">... </span>                               ...          ...     ...  </span><br><span class="line"><span class="number">206205</span>                               <span class="number">0</span>            <span class="number">0</span>       <span class="number">5</span>  </span><br><span class="line"><span class="number">206206</span>                               <span class="number">1</span>            <span class="number">0</span>       <span class="number">0</span>  </span><br><span class="line"><span class="number">206207</span>                              <span class="number">11</span>            <span class="number">0</span>      <span class="number">15</span>  </span><br><span class="line"><span class="number">206208</span>                               <span class="number">0</span>            <span class="number">0</span>      <span class="number">33</span>  </span><br><span class="line"><span class="number">206209</span>                               <span class="number">0</span>            <span class="number">0</span>       <span class="number">3</span>  </span><br><span class="line"></span><br><span class="line">[<span class="number">206209</span> rows x <span class="number">134</span> columns]</span><br><span class="line"></span><br><span class="line">降维后的数据：</span><br><span class="line"> [[-<span class="number">24.21565874</span>   <span class="number">2.4294272</span>   -<span class="number">2.46636975</span> ...  -<span class="number">0.08877715</span>  -<span class="number">0.38087761</span>    <span class="number">0.21568831</span>]</span><br><span class="line"> [  <span class="number">6.46320807</span>  <span class="number">36.75111647</span>   <span class="number">8.38255336</span> ...   <span class="number">1.912145</span>     <span class="number">1.79468946</span>   -<span class="number">0.70142249</span>]</span><br><span class="line"> [ -<span class="number">7.99030162</span>   <span class="number">2.40438257</span> -<span class="number">11.03006405</span> ...  -<span class="number">0.72188348</span>  -<span class="number">1.15719089</span>   -<span class="number">0.23704277</span>]</span><br><span class="line"> ...</span><br><span class="line"> [  <span class="number">8.61143331</span>   <span class="number">7.70129866</span>   <span class="number">7.95240226</span> ...   <span class="number">0.23971061</span>  -<span class="number">0.78590175</span>   -<span class="number">2.65945606</span>]</span><br><span class="line"> [ <span class="number">84.08621987</span>  <span class="number">20.41873398</span>   <span class="number">8.05410372</span> ...  -<span class="number">1.66893212</span>   <span class="number">0.5042934</span>    <span class="number">3.82546312</span>]</span><br><span class="line"> [-<span class="number">13.95345619</span>   <span class="number">6.64621821</span>  -<span class="number">5.23030367</span> ...  -<span class="number">1.64144758</span>  -<span class="number">3.39233648</span>   -<span class="number">0.31410713</span>]]</span><br><span class="line">降维后的维度：</span><br><span class="line"> (<span class="number">206209</span>, <span class="number">44</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/02/sklearn/3_sklearn%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/02/sklearn/3_sklearn%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/" class="post-title-link" itemprop="url">P3_sklearn特征预处理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-02 20:48:00" itemprop="dateCreated datePublished" datetime="2023-11-02T20:48:00+08:00">2023-11-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-05 13:32:36" itemprop="dateModified" datetime="2023-11-05T13:32:36+08:00">2023-11-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="特征工程-特征预处理"><a href="#特征工程-特征预处理" class="headerlink" title="特征工程-特征预处理"></a>特征工程-特征预处理</h1><ul>
<li>学习目标：<ul>
<li>了解数值型数据、类别型数据特点</li>
<li>应用MinMaxScaler实现对特征数据进行归一化</li>
<li>应用StandardScaler实现对特征数据进行标准化<br/></li>
</ul>
</li>
</ul>
<h3 id="什么是特征预处理："><a href="#什么是特征预处理：" class="headerlink" title="什么是特征预处理："></a>什么是特征预处理：</h3><ul>
<li><p>sklearn官方定义：</p>
<ul>
<li>通过<strong>一些转换函数</strong>将特征数据<strong>转换成更适合算法模型</strong>的特征数据过程<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231103110240.png"><br/></li>
</ul>
</li>
<li><p>包含内容：</p>
<ul>
<li>数值型数据的<strong>无量纲化</strong>：<ul>
<li>归一化</li>
<li>标准化<br/></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="为什么要进行归一化、标准化："><a href="#为什么要进行归一化、标准化：" class="headerlink" title="为什么要进行归一化、标准化："></a>为什么要进行归一化、标准化：</h3><ul>
<li>特征的<strong>单位或大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，同意印象（支配）目标结果</strong>，使得一些算法无法学习到其他的特征<br/></li>
</ul>
<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><p>通过原始的数据进行变化吧数据映射的（默认为[0, 1]之间）</p>
</li>
<li><p>公式<br>$$<br>x’ &#x3D; \frac{x - min}{max &#x3D; min} \qquad  x’’ &#x3D; x’ * (mx - mi) + mi<br>$$</p>
<blockquote>
<p>作用于每一列，max为一列的最大值，min为一列的最小值，那么$x’’$为最终结果，mx, mi分别为指定区间默认xmx为1，mi为0</p>
</blockquote>
</li>
<li><p><strong>API</strong></p>
<ul>
<li>sklearn.preprocessing.MinMaxScaler(feature_range&#x3D;(0,1),…)<ul>
<li>MinMaxScalar.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后形状相同的array</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 归一化演示代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、实例化一个转换器类</span></span><br><span class="line">transfer = MinMaxScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new  = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231104110437.png"></p>
</li>
</ul>
<h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><ul>
<li>归一化的问题：<ul>
<li>因为归一化是有最大值与最小值求出的，容易收到异常点的印象，这种方法鲁棒性较差，只适合传统精确小数据场景。</li>
</ul>
</li>
</ul>
<h3 id="定义：-1"><a href="#定义：-1" class="headerlink" title="定义："></a>定义：</h3><ul>
<li><p>通过对原始数据进行变化吧数据变换到均值为0，标准差为1范围内</p>
<br/>
</li>
<li><p>公式：<br>$$<br>X’ &#x3D; \frac{x - mean}{\sigma}<br>$$</p>
<blockquote>
<p>作用于每一列，$mean$为平均值，$\sigma$为标准差</p>
</blockquote>
</li>
<li><p>对于归一化来说：若果出现了异常点，印象了最大值和最小值，那么结果显然会发生改变。</p>
</li>
<li><p>对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</p>
<br/>
</li>
<li><p><strong>API</strong></p>
<ul>
<li>sklearn.preprocseeing.StandardScaler()<ul>
<li>处理之后，对每列来说，所有数据都聚集在均值为0附近，标准差为1</li>
<li>StandardScaler.fit_transform(ndarray[n_samples, n_features])</li>
<li>返回值：转换后的形状相同的array<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化演示代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、调用fit_transform</span></span><br><span class="line">data_new  = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231105110545.png"></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>标准化总结：</strong><br>在已有样本足够多的情况下比较稳定，适合现在嘈杂大数据场景。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/01/sklearn/2_sklearn%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/01/sklearn/2_sklearn%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/" class="post-title-link" itemprop="url">P2_sklearn特征抽取</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-01 10:44:00" itemprop="dateCreated datePublished" datetime="2023-11-01T10:44:00+08:00">2023-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-02 20:50:47" itemprop="dateModified" datetime="2023-11-02T20:50:47+08:00">2023-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="特征工程-数据抽取"><a href="#特征工程-数据抽取" class="headerlink" title="特征工程-数据抽取"></a>特征工程-数据抽取</h2><ul>
<li>特征提取&#x2F;特城抽取定义：将任意数据（如文本或图像）转换为可用于机器学习的数字特征</li>
<li>特征提取的类别：<ul>
<li>字典特征提取（特征离散化）</li>
<li>文本特征提取</li>
<li>图像特征提取（主要在深度学习部分学习）</li>
</ul>
</li>
<li>特征提取api:<ul>
<li>sklearn.feature_extraceion</li>
</ul>
</li>
</ul>
<h3 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h3><ul>
<li><p>作用：对字典数据进行特征值化</p>
</li>
<li><p>sklearn.feature_extraction.DictVectorizer(sparse&#x3D;True, …)</p>
<ul>
<li>DictVectorizer.fit_transform(字典或包含字典的可迭代对象)<ul>
<li>返回值：sparse矩阵</li>
</ul>
</li>
<li>DictVercotizer.inverse_transform(数组或者sparse矩阵)<ul>
<li>返回值：转换之前的数据格式</li>
</ul>
</li>
<li>DictVercotizer.get_feature_names()<ul>
<li>返回值：返回类别名称</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
<ul>
<li>对下面的数据进行特征提取<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">100</span>&#125;,</span><br><span class="line">&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">60</span>&#125;,</span><br><span class="line">&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">30</span>&#125;]</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>流程分析：</p>
<ul>
<li>实例化类：DictVectorizer</li>
<li>调用fit_transform方法输入数据并转换（注意返回格式）</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line">data = [&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">100</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">60</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>: <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>:<span class="number">30</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = DictVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_trancform()方法</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
<p>输出：sparse矩阵（稀疏矩阵）<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101154856.png"></p>
<ul>
<li>如何返回一般矩阵：<ul>
<li>初始化DictVectorizer类时方法拥有一个参数 sparse 若不指定，默认 sparse&#x3D;True 使用关键字参数将其指定为False即可返回一般矩阵</li>
</ul>
</li>
</ul>
<p>修改初始化参数后返回的矩阵：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101155556.png"></p>
<ul>
<li>查看特征值：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="文本特征抽取CountVectorizer"><a href="#文本特征抽取CountVectorizer" class="headerlink" title="文本特征抽取CountVectorizer"></a>文本特征抽取CountVectorizer</h3><ul>
<li><p>作用：对文本数据进行特征值化</p>
</li>
<li><p>sklearn.feature_extraction.text.ConuntVectorizer(stop_words&#x3D;[])</p>
<ul>
<li>返回词频矩阵</li>
</ul>
</li>
<li><p>CountVectorizer.fit_transform(包含文本字符串的可迭代对象)</p>
<ul>
<li>返回 sparse 矩阵</li>
</ul>
</li>
<li><p>CountVectorizer.inverse_atransform(数组或者 sparse 矩阵)</p>
<ul>
<li>返回转换之前的数据格式</li>
</ul>
</li>
<li><p>CountVectorizer.get_feature_names()</p>
<ul>
<li>返回单词列表</li>
</ul>
</li>
<li><p>stop_words：停用词，如果需要过滤无用的单词就添加到列表中传入这个参数。</p>
</li>
<li><p>sklearn.feature_extraceion.text.TfidfVectorizer</p>
</li>
<li><p>示例：</p>
<ul>
<li>对以下数据进行特征提取：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&quot;life is short,i like python&quot;</span>,</span><br><span class="line"><span class="string">&quot;Life is too long,i dislike python&quot;</span>]</span><br></pre></td></tr></table></figure>
演示代码：<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;life is short,i like python&quot;</span>,<span class="string">&quot;Life is too long,i dislike python&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = CountVectorizer()</span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new)</span><br></pre></td></tr></table></figure>
默认输入 sparse 稀疏数组<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data_new：</span><br><span class="line">   (<span class="number">0</span>, <span class="number">2</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">1</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">6</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">3</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">5</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">2</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">1</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">5</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">7</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">4</span>)	<span class="number">1</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">0</span>)	<span class="number">1</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>CountVectorizer转换器没有 sparse 参数，若要输出一般数组，需要使用到 sparse 对象的toarray()方法。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 顺便显示特征名：</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_new.toarray())</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">特征名字：</span><br><span class="line"> [<span class="string">&#x27;dislike&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;life&#x27;</span>, <span class="string">&#x27;like&#x27;</span>, <span class="string">&#x27;long&#x27;</span>, <span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;short&#x27;</span>, <span class="string">&#x27;too&#x27;</span>]</span><br><span class="line">data_new：</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure></li>
<li><p>尝试使用中文句子：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101185826.png"></p>
</li>
<li><p>可以看到转换器把整个句子当做了特征，这显然不是我们想要的效果。</p>
</li>
<li><p>原因是因为CountVertorizer转换器本身是适配英文的，英文的每个单词之间是自带空格的，如果要正确为中文句子提取特征，需要添加空格。<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101191230.png"></p>
</li>
</ul>
<h3 id="CountVectorizer中文文本提取"><a href="#CountVectorizer中文文本提取" class="headerlink" title="CountVectorizer中文文本提取"></a>CountVectorizer中文文本提取</h3><ul>
<li>上面使用中文发现需要手动对词语进行空格隔开，接下要做的事就是自动化这个步骤</li>
<li>借助 jieba 库先将中文文本的词语按词分开，然后再使用转换器提取特征。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人都不要放弃今天。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我们看到的从很远的星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span> ]</span><br><span class="line"></span><br><span class="line">data_new = [<span class="string">&#x27; &#x27;</span>.join(jieba.cut(i)) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化一个转换器类</span></span><br><span class="line">transfer = CountVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_final = transfer.fit_transform(data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_final.toarray())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102202921.png"></li>
</ul>
<h3 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h3><ul>
<li><p>什么是关键词？</p>
<ul>
<li>在某一个类别的文章中，出现的次数很多，但是在其他类别的文章中出现很少</li>
<li>关键词是区分文章类别的关键信息<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102092030.png"></li>
</ul>
</li>
<li><p>TF-IDF</p>
<ul>
<li>TF-IDF的主要是想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的区分类别能力，适合用来分类。</li>
<li>TF-IDF作用：用以评估一个词对于一个文件集或一个语料库中的其中一份文件的重要程度。</li>
</ul>
</li>
<li><p>公式</p>
<ul>
<li>词频（term frequency, tf）指的是某一个给定的词语在该文件中出现的频率</li>
<li>逆向文档频率（inverse document frequency, idf）是一个词语普遍重性的程度。某一特定词语的idf，可以由文件总数目除以包含该词语 的文件的树木，再将得到的商取以10为底的对数得到。<br>$$<br>tfidf_{i,j} &#x3D; tf_{i,j} \times idf_i<br>$$</li>
<li>最终得出结果可以理解为重要程度</li>
</ul>
</li>
<li><p>计算tf-idf例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">有两个词“经济”与“非常”</span><br><span class="line"><span class="number">1000</span>篇文章 - 语料库</span><br><span class="line"><span class="number">100</span>篇文章 - 包含“非常”</span><br><span class="line"><span class="number">10</span>篇文章 - 包含“经济”</span><br><span class="line"></span><br><span class="line">两篇文章：</span><br><span class="line">文章A(<span class="number">100</span>词)：出现<span class="number">10</span>次“经济”</span><br><span class="line">    tf: <span class="number">10</span>/<span class="number">100</span> = <span class="number">0.1</span></span><br><span class="line">    idf: lg <span class="number">1000</span>/<span class="number">10</span> = <span class="number">2</span></span><br><span class="line">文章B(<span class="number">100</span>词)：出现<span class="number">10</span>次“非常”</span><br><span class="line">    tf: <span class="number">10</span>/<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line">    idf: lg <span class="number">1000</span>/<span class="number">100</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">“经济”tf-idf：<span class="number">0.2</span></span><br><span class="line">“非常”tf-idf：<span class="number">0.1</span></span><br></pre></td></tr></table></figure></li>
<li><p>API</p>
<ul>
<li>sklearn.feature_extraction.text.TfidfVectorizer(stop_words&#x3D;None,…)</li>
<li>返回词的权重矩阵<ul>
<li>TfidfVectorizer.fit_transform(文本或包含文本字符串的可迭代对象)<ul>
<li>返回 sparse 矩阵</li>
</ul>
</li>
<li>TfidfVectorizer.inverse_transform(array数组或者sparse矩阵)<ul>
<li>返回转换之前的数据格式</li>
</ul>
</li>
<li>TfidfVectorizer.get_feature_names()<ul>
<li>返回单词列表</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">data = [<span class="string">&quot;今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人都不要放弃今天。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我们看到的从很远的星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span>,</span><br><span class="line">        <span class="string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span> ]</span><br><span class="line"></span><br><span class="line">data_new = [<span class="string">&#x27; &#x27;</span>.join(jieba.cut(i)) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.实例化TfidfVectorizer</span></span><br><span class="line">transfer = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.调用fit_transform</span></span><br><span class="line">data_final = transfer.fit_transform(data_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new：\n&quot;</span>, data_final.toarray())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名字：\n&quot;</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231102202952.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/31/sklearn/1_%E8%8E%B7%E5%8F%96sklearn%E6%95%B0%E6%8D%AE%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/31/sklearn/1_%E8%8E%B7%E5%8F%96sklearn%E6%95%B0%E6%8D%AE%E9%9B%86/" class="post-title-link" itemprop="url">P1_获取sklearn数据集</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-31 19:31:00" itemprop="dateCreated datePublished" datetime="2023-10-31T19:31:00+08:00">2023-10-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-01 10:07:54" itemprop="dateModified" datetime="2023-11-01T10:07:54+08:00">2023-11-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sklearn/" itemprop="url" rel="index"><span itemprop="name">sklearn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="如何获取数据集"><a href="#如何获取数据集" class="headerlink" title="如何获取数据集"></a>如何获取数据集</h2><ul>
<li>使用方法库sklearn.dataset<ul>
<li>加载获取流行数据集（两种方法）</li>
<li><strong>datasets.load_*()</strong><ul>
<li>获取小规模数据集，数据包含在datasets里</li>
</ul>
</li>
<li><strong>satasets.fetch_*(data_home&#x3D;None)</strong><ul>
<li>获取大规模数据集，需要从网络上下载，函数的第一哥参数是data_home，表示数据集下载的目录，默认是~&#x2F;scikit_learn_data&#x2F;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="获取sklearn小数据集"><a href="#获取sklearn小数据集" class="headerlink" title="获取sklearn小数据集"></a>获取sklearn小数据集</h2><ul>
<li>sklearn.datasets.load_iris()<ul>
<li>加载并返回鸢尾花数据集<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="right">数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">类别</td>
<td align="right">3</td>
</tr>
<tr>
<td align="left">特征</td>
<td align="right">4</td>
</tr>
<tr>
<td align="left">样本数量</td>
<td align="right">150</td>
</tr>
<tr>
<td align="left">每个类别数量</td>
<td align="right">50</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li>sklearn.datasets.load_boston()<ul>
<li>加载返回波士顿放假数据集<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="right">数量</th>
</tr>
</thead>
<tbody><tr>
<td align="left">目标类型</td>
<td align="right">5-50</td>
</tr>
<tr>
<td align="left">特征</td>
<td align="right">13</td>
</tr>
<tr>
<td align="left">样本数量</td>
<td align="right">506</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h2 id="获取sklearn大数据集"><a href="#获取sklearn大数据集" class="headerlink" title="获取sklearn大数据集"></a>获取sklearn大数据集</h2><ul>
<li>sklearn.datasets.fetch_20newsgroups(data_home&#x3D;None, subset&#x3D;’train’)<ul>
<li>subset：’train’或者’test’,’all’，可选，选择需要加载的数据集</li>
<li>数据集的“训练”，测试集的“测试”，两者的“全部”</li>
</ul>
</li>
</ul>
<h2 id="sklearn数据集的使用"><a href="#sklearn数据集的使用" class="headerlink" title="sklearn数据集的使用"></a>sklearn数据集的使用</h2><ul>
<li><p>以鸢尾花数据集为例：</p>
</li>
<li><p>特征值4个：花瓣、花萼的长度、宽度</p>
</li>
<li><p>目标值3个：setosa, vericolor, virginica</p>
</li>
<li><p><strong>sklearn数据集返回值介绍：</strong></p>
<ul>
<li>load和fetch返回的数据类型为dataset.base.Bunch（字典格式）<ul>
<li>data：特征数据数组，是 [n_samples * n_features]的二维ndarray数组</li>
<li>target：标签数组，是 n_samples 的以为ndarray数组</li>
<li>DESCR：数据描述</li>
<li>feature_names：特征名，新闻数据、手写数字、回归数据集没有</li>
<li>target_names：标签名</li>
</ul>
</li>
<li>数据集的索引方法：<ul>
<li>dict[“key”] &#x3D; values</li>
<li>bunch.key &#x3D; values</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn加载数据集演示代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;鸢尾花数据集：\n&quot;</span>, iris)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看数据描述：\n&quot;</span>, iris[<span class="string">&quot;DESCR&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值的名字：\n&quot;</span>, iris.feature_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值：\n&quot;</span>, iris.data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;查看特征值shape：\n&quot;</span>, iris.data.shape)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>思考：拿到的数据是否全部都用来训练第一个模型？</strong></p>
<ul>
<li>如果数据全部用来训练模型，就没有数据用来测试。</li>
<li>获取到数据后可以划分为训练集与测试集。</li>
<li>一部分数据用于训练模型，一部分数据用来验证模型的准确度。</li>
</ul>
</blockquote>
<h2 id="数据集的划分"><a href="#数据集的划分" class="headerlink" title="数据集的划分"></a>数据集的划分</h2><ul>
<li><p>机器学习一般分分为两个部分：</p>
<ul>
<li>训练数据：用于训练，构建模型</li>
<li>测试数据：在模型验证时使用，，用于评估模型是否有效</li>
</ul>
</li>
<li><p>划分比例：</p>
<ul>
<li>训练集：70%，80%，75%</li>
<li>测试集：30%，20%，30%</li>
</ul>
</li>
<li><p><strong>数据集划分api：</strong></p>
<ul>
<li>sklearn.model_selection.train_test_split(arrays, *iptions)</li>
<li>参数列表：<ul>
<li>x 数据集的特征值</li>
<li>y 数据集的标签值</li>
<li>test_size 测试集的大小</li>
<li>random_state 随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。</li>
</ul>
</li>
<li>返回值：<ul>
<li>训练集特征值，测试集特征值，训练集目标值，测试集目标值。</li>
<li>一般命名：x_train, x_test, y_train, y_test<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集划分演示代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection.train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.traget, test_size=<span class="number">0.2</span>, random_state=<span class="number">114514</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;数据集的特征值：\n&#x27;</span>, iris.data, iris.data.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;划分后训练集的特征值：\n&#x27;</span>, x_train, x_train.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<div align="center">
   <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101093726.png"  height=130><img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231101093841.png" height=130>
</div>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/31/OpenCV/31_%E5%A4%96%E6%8E%A5%E7%9F%A9%E5%BD%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/31/OpenCV/31_%E5%A4%96%E6%8E%A5%E7%9F%A9%E5%BD%A2/" class="post-title-link" itemprop="url">P31_外接矩形</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-10-31 10:30:00 / 修改时间：15:05:17" itemprop="dateCreated datePublished" datetime="2023-10-31T10:30:00+08:00">2023-10-31</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="最小外接矩形与最大外接矩形"><a href="#最小外接矩形与最大外接矩形" class="headerlink" title="最小外接矩形与最大外接矩形"></a>最小外接矩形与最大外接矩形</h2><ul>
<li>外接矩形氛围最小外接矩形和最大外接矩形.</li>
<li>下图中红色矩形是最小外接矩形，绿色为最大外接矩形.<br>  <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031103244.png"></li>
<li>minAreaRect(points) 最小外接矩形<ul>
<li>points：即轮廓</li>
<li>返回元组，内容是一个旋转矩形(RotatedRect)的参数：矩形的起始坐标x, y,矩形的宽度和高度，矩形的选择角度</li>
</ul>
</li>
<li>boundingRect(points) 最大外接矩形<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入原图</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;wave.png&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">blur_img = cv2.GaussianBlur(gray, (<span class="number">5</span>, <span class="number">5</span>), sigmaX=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># canny</span></span><br><span class="line">canny_img = cv2.Canny(blur_img, <span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轮廓查找，返回两个结果或，轮廓和层级</span></span><br><span class="line">result, contours, hierarchy = cv2.findContours(canny_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line"></span><br><span class="line">img_copy = canny_img.copy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制最小外接矩形与最大外接矩形</span></span><br><span class="line"><span class="comment"># 获取最小外接矩形，返回一个RotatedRect对象rect</span></span><br><span class="line">rect = cv2.minAreaRect(contours[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(rect)</span><br><span class="line"><span class="comment"># boxPoints()函数，帮我们从rect中算出选装矩形的四个坐标点</span></span><br><span class="line"><span class="comment"># 注意坐标必须是整数，使用round()函数对坐标进行四舍五入</span></span><br><span class="line">box = cv2.boxPoints(rect)</span><br><span class="line">box = np.<span class="built_in">round</span>(box).astype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(box)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制最小外接矩形，使用红色</span></span><br><span class="line">cv2.drawContours(img, [box], <span class="number">0</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 获取最大外接矩形,直接返回坐标与长宽四个值</span></span><br><span class="line">x, y, w, h = cv2.boundingRect(contours[<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 使用rectangle()函数直接绘出最大外接矩形，使用绿色以区分</span></span><br><span class="line">cv2.rectangle(img, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line"><span class="comment">#cv2.imshow(&#x27;output&#x27;, np.hstack((img, img_copy)))</span></span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031150008.png"></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/31/OpenCV/30_%E5%A4%9A%E8%BE%B9%E5%BD%A2%E9%80%BC%E8%BF%91%E4%B8%8E%E5%87%B8%E5%8C%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/31/OpenCV/30_%E5%A4%9A%E8%BE%B9%E5%BD%A2%E9%80%BC%E8%BF%91%E4%B8%8E%E5%87%B8%E5%8C%85/" class="post-title-link" itemprop="url">P20_多边形逼近与凸包</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-10-31 10:00:00 / 修改时间：10:30:15" itemprop="dateCreated datePublished" datetime="2023-10-31T10:00:00+08:00">2023-10-31</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="多边形逼近"><a href="#多边形逼近" class="headerlink" title="多边形逼近"></a>多边形逼近</h2><ul>
<li><strong>findContours后轮廓信息contours可能过于复杂不平滑，可以使用approxPolyDP函数对该多边形曲线做适当近似</strong>，这就是轮廓的多边形逼近.</li>
<li>approxPloyDP就是以多边形去逼近轮廓，采用的是Douglas-Peucker算法（方法名中的DP）</li>
<li>DP算法的原理比较简单，核心就是不断找多边形最远的点加入形成新的多边形，知道最短距离小于指定的精度。</li>
<li>approxPolyDP(curve, epsilon, closed[, approxCurve])<ul>
<li>curve：要逼近的轮廓</li>
<li>epsilon：即DP算法使用的阈值</li>
<li>closed：轮廓是否闭合<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用多边形逼近</span></span><br><span class="line">approx = cv2.approxPolyDP(contours[<span class="number">11</span>], <span class="number">20</span>, closed=<span class="literal">True</span>)</span><br><span class="line">cv2.drawContours(img_copy, [approx], <span class="number">0</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031101547.png"></li>
</ul>
</li>
<li>使用多边形逼近，近似模拟手的轮廓.<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入原图</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;hand.png&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">blur_img = cv2.GaussianBlur(gray, (<span class="number">5</span>, <span class="number">5</span>), sigmaX=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># canny</span></span><br><span class="line">canny_img = cv2.Canny(blur_img, <span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轮廓查找，返回两个结果或，轮廓和层级</span></span><br><span class="line">result, contours, hierarchy = cv2.findContours(canny_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(hierarchy)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓会直接修改原图.</span></span><br><span class="line"><span class="comment"># 如果要保持原图不变，可以copy一份</span></span><br><span class="line">img_copy = img.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用多边形逼近</span></span><br><span class="line">approx = cv2.approxPolyDP(contours[<span class="number">1</span>], <span class="number">20</span>, closed=<span class="literal">True</span>)</span><br><span class="line">cv2.drawContours(img_copy, [approx], <span class="number">0</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output&#x27;</span>, np.hstack((img, img_copy)))</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031101900.png"></li>
</ul>
<h2 id="凸包"><a href="#凸包" class="headerlink" title="凸包"></a>凸包</h2><ul>
<li>逼近多边形是轮廓的高度近似，但有的时候，我们更希望使用一个多边形的凸包来简化它。凸包和逼近多边形很像，直播怒过他是物体最外形的凸多边形。凸包指的是完全包含原有的轮廓，并且仅由轮廓上的点所构成的多边形。凸包的每一处都是凸的，即在凸包内连接任意两点的直线都在凸包的内部。在凸包内，任意连续三个点的内角小于180°.</li>
<li>convexHull(points[, hull[, clockwise[, returnPoints]]])<ul>
<li>points：即轮廓</li>
<li>clockwise：顺时针绘制<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入原图</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;hand.png&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">blur_img = cv2.GaussianBlur(gray, (<span class="number">5</span>, <span class="number">5</span>), sigmaX=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># canny</span></span><br><span class="line">canny_img = cv2.Canny(blur_img, <span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轮廓查找，返回两个结果或，轮廓和层级</span></span><br><span class="line">result, contours, hierarchy = cv2.findContours(canny_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(hierarchy)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓会直接修改原图.</span></span><br><span class="line"><span class="comment"># 如果要保持原图不变，可以copy一份</span></span><br><span class="line">img_copy = img.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用多边形逼近</span></span><br><span class="line">approx = cv2.approxPolyDP(contours[<span class="number">1</span>], <span class="number">20</span>, closed=<span class="literal">True</span>)</span><br><span class="line">cv2.drawContours(img_copy, [approx], <span class="number">0</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算凸包</span></span><br><span class="line">hull = cv2.convexHull(contours[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 绘出凸包</span></span><br><span class="line">cv2.drawContours(img_copy, [hull], <span class="number">0</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output&#x27;</span>, np.hstack((img, img_copy)))</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031102723.png"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/31/OpenCV/29_%E8%BD%AE%E5%BB%93%E7%9A%84%E9%9D%A2%E7%A7%AF%E4%B8%8E%E5%91%A8%E9%95%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/31/OpenCV/29_%E8%BD%AE%E5%BB%93%E7%9A%84%E9%9D%A2%E7%A7%AF%E4%B8%8E%E5%91%A8%E9%95%BF/" class="post-title-link" itemprop="url">P29_轮廓的面积与周长</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-10-31 09:36:00 / 修改时间：10:11:36" itemprop="dateCreated datePublished" datetime="2023-10-31T09:36:00+08:00">2023-10-31</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>轮廓面积是每个轮廓中所有的像素点围成区域的面积，单位为像素。</li>
<li>轮廓面积是轮廓重要的统计特性之一，通过轮廓面积的大小可以进一步分析每个轮廓隐含的信息，例如通过轮廓面积区分物体大小识别不同的物体。</li>
</ul>
<p>在查找到轮廓后，可能会有很多细小的轮廓，我们可以通过轮廓的面积进行过滤.</p>
<ul>
<li>contourArea(contour)</li>
<li>arcLength(curve, closed)<ul>
<li>curve及轮廓.</li>
<li>closed是否为闭合的轮廓.<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓会直接修改原图.</span></span><br><span class="line"><span class="comment"># 如果要保持原图不变，可以copy一份</span></span><br><span class="line">img_copy = img.copy()</span><br><span class="line">cv2.drawContours(img_copy, contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算轮廓面积 </span></span><br><span class="line">area = cv2.contourArea(contours[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;area：&#x27;</span>, area)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算轮廓周长</span></span><br><span class="line">perimeter = cv2.arcLength(contours[<span class="number">1</span>], closed=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;rerimeter：&#x27;</span>, perimeter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># area： 0.5</span></span><br><span class="line"><span class="comment"># rerimeter： 82.72792184352875</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/30/OpenCV/28_%E6%9F%A5%E6%89%BE%E4%B8%8E%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="porridge42">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NanBlog 稀饭目标">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/30/OpenCV/28_%E6%9F%A5%E6%89%BE%E4%B8%8E%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93/" class="post-title-link" itemprop="url">P28_查找与绘制轮廓</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-30 20:36:00" itemprop="dateCreated datePublished" datetime="2023-10-30T20:36:00+08:00">2023-10-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-31 09:47:14" itemprop="dateModified" datetime="2023-10-31T09:47:14+08:00">2023-10-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="什么是图像轮廓"><a href="#什么是图像轮廓" class="headerlink" title="什么是图像轮廓"></a>什么是图像轮廓</h2><ul>
<li>图像轮廓是具有相同颜色或灰度的连续点的曲线.轮廓在形状分析和物体的检测和识别中很有用。</li>
<li>轮廓的作用：<ul>
<li>用于图形分析</li>
<li>武德的识别和检测</li>
</ul>
</li>
<li>注意点：<ul>
<li>为了检测的准确性，需要先对图像进行<strong>二值化</strong>或<strong>Canny</strong>操作。</li>
<li>画轮廓时会修改输入的图像，如果之后想继续使用原始图像，应该将原始图像储存到其他变量中。</li>
</ul>
</li>
</ul>
<h2 id="查找轮廓"><a href="#查找轮廓" class="headerlink" title="查找轮廓"></a>查找轮廓</h2><ul>
<li>findContours(image, mode, method[, contours[, hierarchy[, offset]]])<ul>
<li>mode：查找轮廓的模式<ul>
<li>RETR_EXTERNAL &#x3D; 0，表示只检测外轮廓.<br> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231030204248.png"></li>
<li>RETR_LIST &#x3D; 1，检测的轮廓不建立等级关系，即检测所有轮廓，较为常用.<br> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231030204407.png"></li>
<li>RETR_CCOMP &#x3D; 2，每层最多两级，从小到大，从里到外.<br> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231030204535.png"></li>
<li>RETR_TREE &#x3D; 3，按照树形存储，从大到小，从右到左.<br> <img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231030204645.png"></li>
</ul>
</li>
<li>method，轮廓近似方法，也叫ApproximationMode<ul>
<li>CHAIN_APPROX_NONE，保留轮廓上的点</li>
<li>CHAIN_APPROX_SIMPLE，只保存角点，比如四边形，只保留四边形的四个角点，存储信息烧，比较常用</li>
</ul>
</li>
<li>函数返回contouts和hierachy两个值，即轮廓和层级.</li>
</ul>
</li>
</ul>
<h2 id="绘制轮廓"><a href="#绘制轮廓" class="headerlink" title="绘制轮廓"></a>绘制轮廓</h2><ul>
<li>drawContours(image, contours, contourldx, color[, thickness[, lineType[, hierachy[, maxLevel[, offset]]]]])<ul>
<li>image：要绘制轮廓的图像.</li>
<li>contours：轮廓点.</li>
<li>contourldx：要绘制轮廓的编号. -1表示绘制所有轮廓.</li>
<li>color：绘制轮廓线的颜色.</li>
<li>thickness：要绘制轮廓线的线宽. -1表示全部填充.<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入原图</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;maomaochong.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 转换为灰度图</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">blur_img = cv2.GaussianBlur(gray, (<span class="number">5</span>, <span class="number">5</span>), sigmaX=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># canny</span></span><br><span class="line">canny_img = cv2.Canny(blur_img, <span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 轮廓查找，返回两个结果或，轮廓和层级</span></span><br><span class="line">result, contours, hierarchy = cv2.findContours(canny_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓会直接修改原图.</span></span><br><span class="line"><span class="comment"># 如果要保持原图不变，可以copy一份</span></span><br><span class="line">img_copy = img.copy()</span><br><span class="line">cv2.drawContours(img_copy, contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output&#x27;</span>, np.hstack((img, img_copy)))</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<img src="https://raw.githubusercontent.com/porridge42/picgo/main/20231031092656.png"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="porridge42"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">porridge42</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">172</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/porridge42" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;porridge42" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.sorali.org/" title="https:&#x2F;&#x2F;blog.sorali.org" rel="noopener" target="_blank">lisolaris's blog</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">porridge42</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
